{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model_Experimentation_step7_14-8-1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOLnyvHrYhfNcTojChB9q0J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"52AVLV-QKUHY"},"source":["# Model Experimentation\n","\n","In this notebook we will experiment with different deep learning based models for text summarization. In particular, the architecture used here is an encoder-decoder type of network built using LSTM layers. Refer to the literature review notebook for further details on this architecture.\n","\n","In this notebook we will experiment with various settings such as number of hidden dimensions, dropout, size of training data vocabulary, number of LSTM layers, etc.\n","\n","We will use Pytorch to train the models and Tensorboard (integrated with Pytorch) for visualization."]},{"cell_type":"markdown","metadata":{"id":"8ej8yLC6KbIz"},"source":["## Mount Google Drive and Import Libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8BlEalhJt6O","executionInfo":{"status":"ok","timestamp":1618441287043,"user_tz":420,"elapsed":357,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"3cf169b5-6057-4ff0-babf-329510443fe7"},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":116,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kN_j2lJNKABX","executionInfo":{"status":"ok","timestamp":1618441288698,"user_tz":420,"elapsed":255,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"c30e491c-a4f5-44de-b201-ddd349f50f52"},"source":["import sys\n","import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.utils.data as data\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","# for auto-reloading external modules (automatically reloads before using an imported module)\n","%load_ext autoreload\n","%autoreload 2\n","\n","#To ensure that the Colab Python interpreter can load Python files from within\n","PATH_NAME = os.path.join('/', 'content', 'drive', 'My Drive', 'Colab Notebooks', 'UCSDX_MLE_Bootcamp', 'Text_Summarization_UCSD', 'ModelBuilding')\n","sys.path.append(os.path.join(PATH_NAME, 'src'))\n","print(sys.path)\n","%cd $PATH_NAME\n","\n","print(f'Torch version {torch.__version__}')"],"execution_count":117,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/My Drive/Colab Notebooks/UCSDX_MLE_Bootcamp/Text_Summarization_UCSD/ModelBuilding/src', '/content/drive/My Drive/Colab Notebooks/UCSDX_MLE_Bootcamp/Text_Summarization_UCSD/ModelBuilding/src', '/content/drive/My Drive/Colab Notebooks/UCSDX_MLE_Bootcamp/Text_Summarization_UCSD/ModelBuilding/src']\n","/content/drive/My Drive/Colab Notebooks/UCSDX_MLE_Bootcamp/Text_Summarization_UCSD/ModelBuilding\n","Torch version 1.8.1+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sASbLseT2nA","executionInfo":{"status":"ok","timestamp":1618441289914,"user_tz":420,"elapsed":448,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"d8ebffa2-784c-462d-cc53-3c9ca428880d"},"source":["!nvidia-smi"],"execution_count":118,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B764-g_HOmrX"},"source":["## Load Data and Utility Functions\n","We will use cpc_codes 'de' from the BigPatent dataset"]},{"cell_type":"code","metadata":{"id":"URPZY5SHP2Rh","executionInfo":{"status":"ok","timestamp":1618441291613,"user_tz":420,"elapsed":291,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}}},"source":["import utils"],"execution_count":119,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVoKY6IiLYrM","executionInfo":{"status":"ok","timestamp":1618441292380,"user_tz":420,"elapsed":248,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}}},"source":["'''\n","data = utils.load_data_numpy(split_type='train', cpc_codes='de', fname='data0_np.npz')\n","for data_np in data:\n","    print(data_np['data'].shape, data_np['data'][0,0].shape[1], data_np['data'][0,1].shape[1])\n","    print(data_np['data'][0,1])\n","    break\n","del data, data_np\n","''';"],"execution_count":120,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ar2PdtvzfZ8r"},"source":["### Mini Data: Generate vocabulary, word2idx, idx2word, and numpy array\n","\n","Need to do this as the vocabulary for the full dataset is too large for quick prototying and debugging.\n","\n","But try with both, the full vocabulary for the de dataset as well as the vocabulary created from the mini training set."]},{"cell_type":"code","metadata":{"id":"fqZwzx7sz_kc","executionInfo":{"status":"ok","timestamp":1618441294221,"user_tz":420,"elapsed":246,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}}},"source":[""],"execution_count":120,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2E_aYv_utK96"},"source":["## LSTM Based Encoder-Decoder\n","\n","For further details:-\n","\n","https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\n","\n"," http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IYheFFte0gus","executionInfo":{"status":"ok","timestamp":1618441298784,"user_tz":420,"elapsed":3417,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"c6ff28a6-a27e-4cb7-9d8e-eef712a42dc5"},"source":["!pip install rouge"],"execution_count":121,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: rouge in /usr/local/lib/python3.7/dist-packages (1.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WWZP3hElL1-7","executionInfo":{"status":"ok","timestamp":1618441305758,"user_tz":420,"elapsed":222,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}}},"source":["# !touch ../__init__.py\n","# !touch __init__.py\n","# !touch src/__init__.py\n","# !touch ../tests/__init__.py\n","\n","'''\n","then add \n","from ..ModelBuilding.src import models in tests/test_ModelBuilding1.py\n","\n","https://stackoverflow.com/questions/448271/what-is-init-py-for\n","\n","see 5.7 package relative imports at: \n","https://docs.python.org/3/reference/import.html#regular-packages\n","''';"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"As_oDnGXVbGT","executionInfo":{"status":"ok","timestamp":1618441312677,"user_tz":420,"elapsed":3328,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"b3935eb7-3f2e-479c-de1e-059f358d139f"},"source":["#testing\n","!python -m pytest -s ../tests/"],"execution_count":124,"outputs":[{"output_type":"stream","text":["\u001b[1m============================= test session starts ==============================\u001b[0m\n","platform linux -- Python 3.7.10, pytest-3.6.4, py-1.10.0, pluggy-0.7.1\n","rootdir: /content/drive/My Drive/Colab Notebooks/UCSDX_MLE_Bootcamp/Text_Summarization_UCSD, inifile:\n","plugins: typeguard-2.7.1\n","collected 3 items                                                              \u001b[0m\n","\n","../tests/test_ModelBuilding1.py ...\n","\n","\u001b[32m\u001b[1m=========================== 3 passed in 1.44 seconds ===========================\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FOgxhVXaVbp0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7MBYSR8Onw_v","executionInfo":{"status":"ok","timestamp":1618441400568,"user_tz":420,"elapsed":404,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}}},"source":[""],"execution_count":125,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXHJJMcdqMld"},"source":["!python ./src/train.py --hidden_dim 50 --num_layers 2 --batch_size 2 --num_epochs 1 --lr 2e-3 \\\n","                        --print_every_iters 50 --tb_descr 'zzdropout-0_hiddim-50_numlyrs-2_full-de-data'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yaW-2kFGoohE"},"source":["import models\n","import train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"diEaeZ3FqMhK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618440821651,"user_tz":420,"elapsed":17894,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"10cc31b7-ac63-49a5-ebb6-2ae3c31d5c17"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","train_data, val_data, lang_train = train.get_data(use_full_vocab=True, cpc_codes='de', fname='data0_str_json.gz',\n","                                                    train_size=128, val_size=16)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Getting the training data...\n","Size of description vocab is 36828 and abstract vocab is 10769\n","max length (before adding stop token) in mini_df.description is 3943 and in mini_df.abstract (before adding start/stop tokens) is 147\n","(128, 4)\n","max length (before adding stop token) in mini_df.description is 3993 and in mini_df.abstract (before adding start/stop tokens) is 140\n","(16, 4)\n","Data shape is: torch.Size([128, 4000]), torch.Size([128, 150]), torch.Size([128])\n","Total data size is: 2.125MB\n","Data shape is: torch.Size([16, 4000]), torch.Size([16, 150]), torch.Size([16])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tyrVj0AIfsth"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lNjY0SHuLWIj"},"source":["#### Seq2Seq: lr=0.002, dropout=0.0, hiddim=50, numlyrs=2, full-de-vocab, train_size=128, val_size=16"]},{"cell_type":"code","metadata":{"id":"FXoQFdzCGDx3"},"source":["%%timeit -r 1 -n 1\n","#using the full vocab/word2idx/idx2word from the de dataset (train_size=128, val_size=16)\n","#make sure have same number of layers for both encoder and decoder\n","encoder = models.EncoderLSTM(vocab_size=len(lang_train.desc_vocab), hidden_dim=50, num_layers=2, bidir=True)\n","decoder = models.DecoderLSTM(vocab_size=len(lang_train.abs_vocab), hidden_dim=50, num_layers=2, bidir=False)\n","model = models.Seq2Seq(encoder, decoder)\n","\n","train.train(model=model, train_data=train_data, val_data=val_data, abs_idx2word=lang_train.abs_idx2word, device=device, \n","            batch_size=128, num_epochs=300, lr=2e-3, print_every_iters=250, tb_descr='dropout-0_hiddim-50_numlyrs-2_full-de-data')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zacgmBPaKckK"},"source":["Training Loss |Training Data Rouge | Validation Data Rouge\n","--- | --- | ---\n","![](https://drive.google.com/uc?export=view&id=1Kf7zitCVM8_7V1GsmQLbYttLWU9hqgDv) | ![](https://drive.google.com/uc?export=view&id=1Ng2IWaG9rRoLaQELqWBVfqUiB3lkrVBD) | ![](https://drive.google.com/uc?export=view&id=1a4DN6uOJky9tyZ2WyOd1GCTUzIkFkj8F)\n","| Dark Blue: Rouge-1, Red: Rouge-2, Light Blue: Rouge-l | Pink: Rouge-1, Green: Rouge-2, Gray: Rouge-l"]},{"cell_type":"code","metadata":{"id":"mp00GyHvlPxh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QwkqvzVxLege"},"source":["#### Seq2Seq: lr=0.002, dropout=0.0, hiddim=100, numlyrs=2, vocab generated from 128 training examples, train_size=128, val_size=16"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UtWokKqlP1Q","executionInfo":{"status":"ok","timestamp":1617341893988,"user_tz":420,"elapsed":2096720,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"9901e902-b2f3-4e2e-c344-db65510c1948"},"source":["%%timeit -r 1 -n 1\n","#make sure have same number of layers for both encoder and decoder (train_size=128, val_size=16)\n","encoder = models.EncoderLSTM(vocab_size=len(lang_train.desc_vocab), hidden_dim=100, num_layers=2, bidir=True)\n","decoder = models.DecoderLSTM(vocab_size=len(lang_train.abs_vocab), hidden_dim=100, num_layers=2, bidir=False)\n","model = models.Seq2Seq(encoder, decoder)\n","\n","train.train(model=model, train_data=train_data, val_data=val_data, abs_idx2word=lang_train.abs_idx2word, device=device, \n","            batch_size=128, num_epochs=2500, lr=2e-3, print_every_iters=250, tb_descr='dropout-0_hiddim-100_numlyrs-2')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["After Iteration 0, Loss is: 7.773667\n","\tModel eval on training data after iteration 0...\n","\t\tRouge-1 is 0.0004, Rouge-2 is 0.0000, and Rouge-l is 0.0013\n","\tModel eval on validation data after iteration 0...\n","\t\tRouge-1 is 0.0000, Rouge-2 is 0.0000, and Rouge-l is 0.0000\n","After Iteration 250, Loss is: 5.875730\n","\tModel eval on training data after iteration 250...\n","\t\tRouge-1 is 0.1582, Rouge-2 is 0.0106, and Rouge-l is 0.1518\n","\tModel eval on validation data after iteration 250...\n","\t\tRouge-1 is 0.1653, Rouge-2 is 0.0091, and Rouge-l is 0.1676\n","After Iteration 500, Loss is: 4.404660\n","\tModel eval on training data after iteration 500...\n","\t\tRouge-1 is 0.1582, Rouge-2 is 0.0213, and Rouge-l is 0.1611\n","\tModel eval on validation data after iteration 500...\n","\t\tRouge-1 is 0.1539, Rouge-2 is 0.0208, and Rouge-l is 0.1720\n","After Iteration 750, Loss is: 2.953698\n","\tModel eval on training data after iteration 750...\n","\t\tRouge-1 is 0.2504, Rouge-2 is 0.0370, and Rouge-l is 0.1456\n","\tModel eval on validation data after iteration 750...\n","\t\tRouge-1 is 0.2395, Rouge-2 is 0.0400, and Rouge-l is 0.1588\n","After Iteration 1000, Loss is: 2.042944\n","\tModel eval on training data after iteration 1000...\n","\t\tRouge-1 is 0.2295, Rouge-2 is 0.0248, and Rouge-l is 0.1512\n","\tModel eval on validation data after iteration 1000...\n","\t\tRouge-1 is 0.2337, Rouge-2 is 0.0187, and Rouge-l is 0.1563\n","After Iteration 1250, Loss is: 1.393816\n","\tModel eval on training data after iteration 1250...\n","\t\tRouge-1 is 0.2293, Rouge-2 is 0.0291, and Rouge-l is 0.1593\n","\tModel eval on validation data after iteration 1250...\n","\t\tRouge-1 is 0.2187, Rouge-2 is 0.0169, and Rouge-l is 0.1587\n","After Iteration 1500, Loss is: 0.940939\n","\tModel eval on training data after iteration 1500...\n","\t\tRouge-1 is 0.2286, Rouge-2 is 0.0179, and Rouge-l is 0.1531\n","\tModel eval on validation data after iteration 1500...\n","\t\tRouge-1 is 0.2272, Rouge-2 is 0.0122, and Rouge-l is 0.1553\n","After Iteration 1750, Loss is: 0.609870\n","\tModel eval on training data after iteration 1750...\n","\t\tRouge-1 is 0.2319, Rouge-2 is 0.0229, and Rouge-l is 0.1867\n","\tModel eval on validation data after iteration 1750...\n","\t\tRouge-1 is 0.2163, Rouge-2 is 0.0121, and Rouge-l is 0.1736\n","After Iteration 2000, Loss is: 0.395601\n","\tModel eval on training data after iteration 2000...\n","\t\tRouge-1 is 0.2319, Rouge-2 is 0.0229, and Rouge-l is 0.1867\n","\tModel eval on validation data after iteration 2000...\n","\t\tRouge-1 is 0.2163, Rouge-2 is 0.0121, and Rouge-l is 0.1736\n","After Iteration 2250, Loss is: 0.264211\n","\tModel eval on training data after iteration 2250...\n","\t\tRouge-1 is 0.2319, Rouge-2 is 0.0229, and Rouge-l is 0.1867\n","\tModel eval on validation data after iteration 2250...\n","\t\tRouge-1 is 0.2163, Rouge-2 is 0.0121, and Rouge-l is 0.1736\n","\n","Model eval on validation data after final iteration...\n","Example\n","Prediction\n","a method of producing and arrangement for a multi - pane insulating glass structure which has two parallel panes , a frame for holding the panes and an adhesive sealant mounted between the panes and the frame , comprises specially - shaped elongated plastic sectional rods forming portions of the frame and having grooves for receiving the panes with a foil - type vapor seal mounted intermediate first and second ones of the sectional rod portions . the first rod portion is substantially u - shaped in cross - section and forms a spacer for the spaced parallel panes . the u - shaped sectional rod includes a central web for spanning the foil - type vapor seal and forming a chamber for housing a moisture - absorbing agent . --stop--\n","Target\n","an apparatus for --oov-- an eccentrically located well bore device is disclosed . one embodiment of the apparatus comprises : a main body attachable to a --oov-- member ; an arm --oov-- to the main body ; a lock assembly for selectively retaining the arm in a locked position and --oov-- the arm from the locked position ; a --oov-- over assembly for moving the arm to a --oov-- over position ; and an --oov-- connected to the lift arm , the --oov-- connectable with a tool for latching onto the device . the --oov-- over assembly comprises a --oov-- member operatively connected to the arm and a --oov-- member having a first end connected to the arm and a second end connected to the --oov-- member . --stop-- --null-- --null--\n","Rouge-1 is 0.2702, Rouge-2 is 0.0874, and Rouge-l is 0.1875\n","1 loop, best of 1: 34min 52s per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WVhyxi0clP4T"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EukZlRbyL120"},"source":["#### Seq2Seq: lr=0.002, dropout=0.2, hiddim=100, numlyrs=2, vocab generated from 128 training examples, train_size=128, val_size=16"]},{"cell_type":"code","metadata":{"id":"d01BgrkdlP6m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617421443398,"user_tz":420,"elapsed":3570548,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"ad0f67c4-ec1d-44ce-ca23-08ce07b04c43"},"source":["%%timeit -r 1 -n 1\n","#make sure have same number of layers for both encoder and decoder (train_size=128, val_size=16)\n","encoder = models.EncoderLSTM(vocab_size=len(lang_train.desc_vocab), hidden_dim=100, num_layers=2, bidir=True, dropout=0.2)\n","decoder = models.DecoderLSTM(vocab_size=len(lang_train.abs_vocab), hidden_dim=100, num_layers=2, bidir=False, dropout=0.2)\n","model = models.Seq2Seq(encoder, decoder)\n","\n","train.train(model=model, train_data=train_data, val_data=val_data, abs_idx2word=lang_train.abs_idx2word, device=device, \n","            batch_size=128, num_epochs=3500, lr=2e-3, print_every_iters=250, tb_descr='dropout-0p2_hiddim-100_numlyrs-2')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["After Iteration 0, Loss is: 7.825840\n","\tModel eval on training data after iteration 0...\n","\t\tRouge-1 is 0.0555, Rouge-2 is 0.0001, and Rouge-l is 0.0408\n","\tModel eval on validation data after iteration 0...\n","\t\tRouge-1 is 0.0557, Rouge-2 is 0.0000, and Rouge-l is 0.0470\n","After Iteration 250, Loss is: 5.781209\n","\tModel eval on training data after iteration 250...\n","\t\tRouge-1 is 0.2227, Rouge-2 is 0.0280, and Rouge-l is 0.1415\n","\tModel eval on validation data after iteration 250...\n","\t\tRouge-1 is 0.2102, Rouge-2 is 0.0289, and Rouge-l is 0.1569\n","After Iteration 500, Loss is: 4.535874\n","\tModel eval on training data after iteration 500...\n","\t\tRouge-1 is 0.2484, Rouge-2 is 0.0415, and Rouge-l is 0.1804\n","\tModel eval on validation data after iteration 500...\n","\t\tRouge-1 is 0.2547, Rouge-2 is 0.0407, and Rouge-l is 0.2007\n","After Iteration 750, Loss is: 3.241772\n","\tModel eval on training data after iteration 750...\n","\t\tRouge-1 is 0.2728, Rouge-2 is 0.0481, and Rouge-l is 0.1823\n","\tModel eval on validation data after iteration 750...\n","\t\tRouge-1 is 0.2574, Rouge-2 is 0.0404, and Rouge-l is 0.1754\n","After Iteration 1000, Loss is: 2.382757\n","\tModel eval on training data after iteration 1000...\n","\t\tRouge-1 is 0.2720, Rouge-2 is 0.0461, and Rouge-l is 0.1779\n","\tModel eval on validation data after iteration 1000...\n","\t\tRouge-1 is 0.2470, Rouge-2 is 0.0325, and Rouge-l is 0.1680\n","After Iteration 1250, Loss is: 1.726882\n","\tModel eval on training data after iteration 1250...\n","\t\tRouge-1 is 0.2862, Rouge-2 is 0.0621, and Rouge-l is 0.2027\n","\tModel eval on validation data after iteration 1250...\n","\t\tRouge-1 is 0.2551, Rouge-2 is 0.0300, and Rouge-l is 0.1863\n","After Iteration 1500, Loss is: 1.209939\n","\tModel eval on training data after iteration 1500...\n","\t\tRouge-1 is 0.3543, Rouge-2 is 0.1508, and Rouge-l is 0.2974\n","\tModel eval on validation data after iteration 1500...\n","\t\tRouge-1 is 0.2458, Rouge-2 is 0.0292, and Rouge-l is 0.1705\n","After Iteration 1750, Loss is: 0.814861\n","\tModel eval on training data after iteration 1750...\n","\t\tRouge-1 is 0.4004, Rouge-2 is 0.2236, and Rouge-l is 0.3598\n","\tModel eval on validation data after iteration 1750...\n","\t\tRouge-1 is 0.2492, Rouge-2 is 0.0257, and Rouge-l is 0.1744\n","After Iteration 2000, Loss is: 0.533207\n","\tModel eval on training data after iteration 2000...\n","\t\tRouge-1 is 0.4804, Rouge-2 is 0.3313, and Rouge-l is 0.4552\n","\tModel eval on validation data after iteration 2000...\n","\t\tRouge-1 is 0.2383, Rouge-2 is 0.0174, and Rouge-l is 0.1665\n","After Iteration 2250, Loss is: 0.352639\n","\tModel eval on training data after iteration 2250...\n","\t\tRouge-1 is 0.5743, Rouge-2 is 0.4513, and Rouge-l is 0.5593\n","\tModel eval on validation data after iteration 2250...\n","\t\tRouge-1 is 0.2265, Rouge-2 is 0.0272, and Rouge-l is 0.1815\n","After Iteration 2500, Loss is: 0.238518\n","\tModel eval on training data after iteration 2500...\n","\t\tRouge-1 is 0.6350, Rouge-2 is 0.5304, and Rouge-l is 0.6204\n","\tModel eval on validation data after iteration 2500...\n","\t\tRouge-1 is 0.2398, Rouge-2 is 0.0248, and Rouge-l is 0.1724\n","After Iteration 2750, Loss is: 0.173244\n","\tModel eval on training data after iteration 2750...\n","\t\tRouge-1 is 0.7248, Rouge-2 is 0.6467, and Rouge-l is 0.7152\n","\tModel eval on validation data after iteration 2750...\n","\t\tRouge-1 is 0.2408, Rouge-2 is 0.0265, and Rouge-l is 0.1856\n","After Iteration 3000, Loss is: 0.131800\n","\tModel eval on training data after iteration 3000...\n","\t\tRouge-1 is 0.7467, Rouge-2 is 0.6736, and Rouge-l is 0.7359\n","\tModel eval on validation data after iteration 3000...\n","\t\tRouge-1 is 0.2325, Rouge-2 is 0.0245, and Rouge-l is 0.1840\n","After Iteration 3250, Loss is: 0.098397\n","\tModel eval on training data after iteration 3250...\n","\t\tRouge-1 is 0.8042, Rouge-2 is 0.7468, and Rouge-l is 0.7966\n","\tModel eval on validation data after iteration 3250...\n","\t\tRouge-1 is 0.2322, Rouge-2 is 0.0263, and Rouge-l is 0.1866\n","\n","Model eval on validation data after final iteration...\n","Example\n","Prediction\n","apparatus for washing and / or dewatering cellulose pulp is disclosed including a movable permeable surface in a pulp transportation chamber having a chamber gap above the movable permeable surface , a pulp distributor for distributing pulp onto the movable permeable surface , a throttle having a throttle gap width and an adjustable throttle adjuster to remotely adjust the throttle gap width so that a volume of pulp flow into the pulp distributor is equal to or greater than the volume of pulp flow out of the distributor during operation . --stop--                                            \n","Target\n","in one embodiment , the present invention provides a free - --oov-- --oov-- --oov-- for storing multiple --oov-- in a single column vertical --oov-- arrangement . in another embodiment the invention provides a --oov-- --oov-- for storing multiple --oov-- in a single column vertical --oov-- arrangement wherein the --oov-- --oov-- is --oov-- or inserted for permanent or --oov-- attachment to the inside of a --oov-- safe . in one aspect of this embodiment , the --oov-- --oov-- is configured to a height and width that --oov-- up about the same amount of space as a long --oov-- if such long --oov-- were disposed or secured in a vertical position in the same space within the --oov-- safe . --stop--                 \n","Rouge-1 is 0.2310, Rouge-2 is 0.0203, and Rouge-l is 0.1846\n","1 loop, best of 1: 59min 26s per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gdroy1-4K606"},"source":["Training Loss |Training Data Rouge | Validation Data Rouge\n","--- | --- | ---\n","![](https://drive.google.com/uc?export=view&id=1kAlMYvIaPsl0M8J2c-kasY8YfAW6Ho77) | ![](https://drive.google.com/uc?export=view&id=1LffsjVI7Yck9lXRBxa2p7YXAt6Ht2X6c) | ![](https://drive.google.com/uc?export=view&id=18LqZ-oSPAMJFBfuAKFNJ3nzn11LrX5NX)\n","| Dark Blue: Rouge-1, Red: Rouge-2, Light Blue: Rouge-l | Pink: Rouge-1, Green: Rouge-2, Gray: Rouge-l\n"]},{"cell_type":"code","metadata":{"id":"5CAQ9fDgi1TP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x1BK7nqRMACr"},"source":["#### Seq2Seq: lr=0.002, dropout=0.2, hiddim=100, numlyrs=2, full de vocab, train_size=128, val_size=16"]},{"cell_type":"code","metadata":{"id":"fe2YtTXu_dc_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617417744020,"user_tz":420,"elapsed":2676956,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"26569d9e-7b6b-40c0-a086-267d4212df0a"},"source":["%%timeit -r 1 -n 1\n","#using the full vocab/word2idx/idx2word from the de dataset (train_size=128, val_size=16)\n","#make sure have same number of layers for both encoder and decoder\n","encoder = models.EncoderLSTM(vocab_size=len(lang_train.desc_vocab), hidden_dim=100, num_layers=2, bidir=True, dropout=0.2)\n","decoder = models.DecoderLSTM(vocab_size=len(lang_train.abs_vocab), hidden_dim=100, num_layers=2, bidir=False, dropout=0.2)\n","model = models.Seq2Seq(encoder, decoder)\n","\n","train.train(model=model, train_data=train_data, val_data=val_data, abs_idx2word=lang_train.abs_idx2word, device=device, \n","            batch_size=128, num_epochs=2500, lr=2e-3, print_every_iters=250, tb_descr='dropout-0p2_hiddim-100_numlyrs-2_full-de-vocab')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["After Iteration 0, Loss is: 9.306280\n","\tModel eval on training data after iteration 0...\n","\t\tRouge-1 is 0.0016, Rouge-2 is 0.0000, and Rouge-l is 0.0052\n","\tModel eval on validation data after iteration 0...\n","\t\tRouge-1 is 0.0010, Rouge-2 is 0.0000, and Rouge-l is 0.0047\n","After Iteration 250, Loss is: 6.714604\n","\tModel eval on training data after iteration 250...\n","\t\tRouge-1 is 0.0913, Rouge-2 is 0.0000, and Rouge-l is 0.0718\n","\tModel eval on validation data after iteration 250...\n","\t\tRouge-1 is 0.0952, Rouge-2 is 0.0000, and Rouge-l is 0.0704\n","After Iteration 500, Loss is: 6.069162\n","\tModel eval on training data after iteration 500...\n","\t\tRouge-1 is 0.1487, Rouge-2 is 0.0065, and Rouge-l is 0.1274\n","\tModel eval on validation data after iteration 500...\n","\t\tRouge-1 is 0.1547, Rouge-2 is 0.0049, and Rouge-l is 0.1297\n","After Iteration 750, Loss is: 5.183101\n","\tModel eval on training data after iteration 750...\n","\t\tRouge-1 is 0.2089, Rouge-2 is 0.0305, and Rouge-l is 0.1989\n","\tModel eval on validation data after iteration 750...\n","\t\tRouge-1 is 0.2140, Rouge-2 is 0.0319, and Rouge-l is 0.1874\n","After Iteration 1000, Loss is: 3.923828\n","\tModel eval on training data after iteration 1000...\n","\t\tRouge-1 is 0.2728, Rouge-2 is 0.0456, and Rouge-l is 0.1855\n","\tModel eval on validation data after iteration 1000...\n","\t\tRouge-1 is 0.2776, Rouge-2 is 0.0425, and Rouge-l is 0.1926\n","After Iteration 1250, Loss is: 2.871156\n","\tModel eval on training data after iteration 1250...\n","\t\tRouge-1 is 0.2706, Rouge-2 is 0.0409, and Rouge-l is 0.1810\n","\tModel eval on validation data after iteration 1250...\n","\t\tRouge-1 is 0.2547, Rouge-2 is 0.0347, and Rouge-l is 0.1660\n","After Iteration 1500, Loss is: 2.117717\n","\tModel eval on training data after iteration 1500...\n","\t\tRouge-1 is 0.2686, Rouge-2 is 0.0402, and Rouge-l is 0.1778\n","\tModel eval on validation data after iteration 1500...\n","\t\tRouge-1 is 0.2704, Rouge-2 is 0.0294, and Rouge-l is 0.1635\n","After Iteration 1750, Loss is: 1.536921\n","\tModel eval on training data after iteration 1750...\n","\t\tRouge-1 is 0.2778, Rouge-2 is 0.0511, and Rouge-l is 0.2013\n","\tModel eval on validation data after iteration 1750...\n","\t\tRouge-1 is 0.2528, Rouge-2 is 0.0357, and Rouge-l is 0.1738\n","After Iteration 2000, Loss is: 1.065314\n","\tModel eval on training data after iteration 2000...\n","\t\tRouge-1 is 0.3091, Rouge-2 is 0.0935, and Rouge-l is 0.2389\n","\tModel eval on validation data after iteration 2000...\n","\t\tRouge-1 is 0.2474, Rouge-2 is 0.0322, and Rouge-l is 0.1588\n","After Iteration 2250, Loss is: 0.710262\n","\tModel eval on training data after iteration 2250...\n","\t\tRouge-1 is 0.3864, Rouge-2 is 0.2060, and Rouge-l is 0.3499\n","\tModel eval on validation data after iteration 2250...\n","\t\tRouge-1 is 0.2570, Rouge-2 is 0.0314, and Rouge-l is 0.1678\n","\n","Model eval on validation data after final iteration...\n","Example\n","Prediction\n","a weaving machine is operationally connected to a shed - forming machine which includes a drive shaft and a braking mechanism . the latter includes a braking disk which is axially slidably supported on the drive shaft , each c at least one c --#number#-- to c --#number#-- alkylene oxide , and a minor amount of a cross - sectional shape . the --oov-- counterbalance is configured to create a programmable logic controller . --stop--                                                                                                    \n","Target\n","a sun control textile with high transmittance and a manufacturing method thereof . in the manufacturing method of the sun control textile , a high - performance sun control film is processed into slender filaments . the slender filaments are woven and assembled with other yarns by a weaving device to together form a sun control textile . the different connection manners of the sun control film yarns lead to different visible light transmittance and sun control effect of the sun control textile , whereby an excellent sun control textile with high transmittance can be achieved . --stop--                                                   \n","Rouge-1 is 0.2718, Rouge-2 is 0.0321, and Rouge-l is 0.1811\n","1 loop, best of 1: 44min 33s per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FeL-taUeLGHf"},"source":["Training Loss |Training Data Rouge | Validation Data Rouge\n","--- | --- | ---\n","![](https://drive.google.com/uc?export=view&id=1AjN7dYoinJ7jdhGvcYXmnOyK9YvlKleA) | ![](https://drive.google.com/uc?export=view&id=1vDXrVreM9fzYs4qEdFWcF4YeQE1LZd02) | ![](https://drive.google.com/uc?export=view&id=1IbbRKXkcn2yus053zsx17stB6Grw_Op-)\n","| Dark Blue: Rouge-1, Red: Rouge-2, Light Blue: Rouge-l | Pink: Rouge-1, Green: Rouge-2, Gray: Rouge-l\n"]},{"cell_type":"code","metadata":{"id":"u8MRgEbIBUAp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kgSS5i6JMRkI"},"source":["#### Seq2Seq: lr=0.002, dropout=0.3, hiddim=100, numlyrs=2, full-de-vocab, train_size=128, val_size=16"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ILsxU7rABUUB","executionInfo":{"status":"ok","timestamp":1617427372368,"user_tz":420,"elapsed":2697700,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"6b31af41-db76-4576-b605-c2e5050666dc"},"source":["%%timeit -r 1 -n 1\n","#using the full vocab/word2idx/idx2word from the de dataset (train_size=128 and val_size=16)\n","#make sure have same number of layers for both encoder and decoder\n","encoder = models.EncoderLSTM(vocab_size=len(lang_train.desc_vocab), hidden_dim=100, num_layers=2, bidir=True, dropout=0.3)\n","decoder = models.DecoderLSTM(vocab_size=len(lang_train.abs_vocab), hidden_dim=100, num_layers=2, bidir=False, dropout=0.3)\n","model = models.Seq2Seq(encoder, decoder)\n","\n","train.train(model=model, train_data=train_data, val_data=val_data, abs_idx2word=lang_train.abs_idx2word, device=device, \n","            batch_size=128, num_epochs=2500, lr=2e-3, print_every_iters=250, tb_descr='dropout-0p3_hiddim-100_numlyrs-2_full-de-vocab')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["After Iteration 0, Loss is: 9.304827\n","\tModel eval on training data after iteration 0...\n","\t\tRouge-1 is 0.0003, Rouge-2 is 0.0000, and Rouge-l is 0.0011\n","\tModel eval on validation data after iteration 0...\n","\t\tRouge-1 is 0.0000, Rouge-2 is 0.0000, and Rouge-l is 0.0000\n","After Iteration 250, Loss is: 6.736654\n","\tModel eval on training data after iteration 250...\n","\t\tRouge-1 is 0.0913, Rouge-2 is 0.0000, and Rouge-l is 0.0718\n","\tModel eval on validation data after iteration 250...\n","\t\tRouge-1 is 0.0952, Rouge-2 is 0.0000, and Rouge-l is 0.0704\n","After Iteration 500, Loss is: 5.781800\n","\tModel eval on training data after iteration 500...\n","\t\tRouge-1 is 0.1210, Rouge-2 is 0.0120, and Rouge-l is 0.1623\n","\tModel eval on validation data after iteration 500...\n","\t\tRouge-1 is 0.1240, Rouge-2 is 0.0108, and Rouge-l is 0.1655\n","After Iteration 750, Loss is: 4.726680\n","\tModel eval on training data after iteration 750...\n","\t\tRouge-1 is 0.1668, Rouge-2 is 0.0253, and Rouge-l is 0.1811\n","\tModel eval on validation data after iteration 750...\n","\t\tRouge-1 is 0.1762, Rouge-2 is 0.0270, and Rouge-l is 0.1776\n","After Iteration 1000, Loss is: 3.661641\n","\tModel eval on training data after iteration 1000...\n","\t\tRouge-1 is 0.2784, Rouge-2 is 0.0447, and Rouge-l is 0.1876\n","\tModel eval on validation data after iteration 1000...\n","\t\tRouge-1 is 0.2580, Rouge-2 is 0.0375, and Rouge-l is 0.1698\n","After Iteration 1250, Loss is: 2.798471\n","\tModel eval on training data after iteration 1250...\n","\t\tRouge-1 is 0.2645, Rouge-2 is 0.0410, and Rouge-l is 0.1749\n","\tModel eval on validation data after iteration 1250...\n","\t\tRouge-1 is 0.2549, Rouge-2 is 0.0361, and Rouge-l is 0.1542\n","After Iteration 1500, Loss is: 2.139048\n","\tModel eval on training data after iteration 1500...\n","\t\tRouge-1 is 0.2635, Rouge-2 is 0.0378, and Rouge-l is 0.1775\n","\tModel eval on validation data after iteration 1500...\n","\t\tRouge-1 is 0.2479, Rouge-2 is 0.0394, and Rouge-l is 0.1601\n","After Iteration 1750, Loss is: 1.603324\n","\tModel eval on training data after iteration 1750...\n","\t\tRouge-1 is 0.2556, Rouge-2 is 0.0379, and Rouge-l is 0.1692\n","\tModel eval on validation data after iteration 1750...\n","\t\tRouge-1 is 0.2488, Rouge-2 is 0.0315, and Rouge-l is 0.1665\n","After Iteration 2000, Loss is: 1.169262\n","\tModel eval on training data after iteration 2000...\n","\t\tRouge-1 is 0.2554, Rouge-2 is 0.0357, and Rouge-l is 0.1694\n","\tModel eval on validation data after iteration 2000...\n","\t\tRouge-1 is 0.2377, Rouge-2 is 0.0289, and Rouge-l is 0.1636\n","After Iteration 2250, Loss is: 0.820907\n","\tModel eval on training data after iteration 2250...\n","\t\tRouge-1 is 0.2567, Rouge-2 is 0.0351, and Rouge-l is 0.1723\n","\tModel eval on validation data after iteration 2250...\n","\t\tRouge-1 is 0.2517, Rouge-2 is 0.0326, and Rouge-l is 0.1581\n","\n","Model eval on validation data after final iteration...\n","Example\n","Prediction\n","a method and a process for producing the pile loops are controlled of the earth needle whose system is driven by the roof . the upper device is used as a --oov-- and with the top of the water includes a base of a pressure duration formed . --stop--                                                                                                                   \n","Target\n","identical metal trough sections adapted for twist - lock attachment end to end . the twist - lock arrangement is built into the trough sections . no separate fasteners are required . the attached trough sections produce a half - round elongated member . the elongated member is useful for supporting and protecting --oov-- flexible sewer hose of the type normally used on motor homes and trailers for emptying holding tanks . after use , the elongated support member can be --oov-- back into the smaller trough sections for storage . --stop--                                                         \n","Rouge-1 is 0.2654, Rouge-2 is 0.0322, and Rouge-l is 0.1748\n","1 loop, best of 1: 44min 54s per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TBTYN66aT1V8"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BB5xKijnMagY"},"source":["#### Seq2Seq: lr=0.002, dropout=0.2, hiddim=100, numlyrs=2, full-de-vocab, train_size=512, val_size=16"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WSFA764gEgXs","executionInfo":{"status":"ok","timestamp":1617475826865,"user_tz":420,"elapsed":13280,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"8194b2d6-e62a-4a8a-af47-73dd56ae8549"},"source":["data_train = utils.load_data_string(split_type='train', cpc_codes='de', fname='data0_str_json.gz')\n","data_val = utils.load_data_string(split_type='val', cpc_codes='de', fname='data0_str_json.gz')\n","mini_df_train = get_mini_df(data_train, mini_df_size=512) \n","mini_df_val = get_mini_df(data_val, mini_df_size=16) \n","#--------------------------------------------------------------------------------------------\n","lang_train = utils.Mini_Data_Language_Info(mini_df_train, desc_word2idx=desc_word2idx,abs_word2idx=abs_word2idx,\n","                                           desc_idx2word=desc_idx2word, abs_idx2word=abs_idx2word,\n","                                           desc_vocab=desc_vocab, abs_vocab=abs_vocab)\n","# lang_train = utils.Mini_Data_Language_Info(mini_df_train) #generate vocab etc\n","lang_val = utils.Mini_Data_Language_Info(mini_df_val, desc_word2idx=lang_train.desc_word2idx,abs_word2idx=lang_train.abs_word2idx)\n","#---------------------------------------------------------------------------------------------\n","train_data = utils.bigPatentDataset(lang_train.mini_data, shuffle=True)\n","train_data.memory_size()\n","val_data = utils.bigPatentDataset(lang_val.mini_data, shuffle=True)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["max length (before adding stop token) in mini_df.description is 3974 and in mini_df.abstract (before adding start/stop tokens) is 149\n","(512, 4)\n","max length (before adding stop token) in mini_df.description is 3993 and in mini_df.abstract (before adding start/stop tokens) is 140\n","(16, 4)\n","Data shape is: torch.Size([512, 4000]), torch.Size([512, 150]), torch.Size([512])\n","Total data size is: 8.500MB\n","Data shape is: torch.Size([16, 4000]), torch.Size([16, 150]), torch.Size([16])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DAYJj7EgT1j2","executionInfo":{"status":"ok","timestamp":1617475099263,"user_tz":420,"elapsed":12008050,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"3d5a8860-1bd5-454e-d30c-8f500aa7dc07"},"source":["%%timeit -r 1 -n 1\n","#using the full vocab/word2idx/idx2word from the de dataset (train_size=512, val_size=16)\n","#make sure have same number of layers for both encoder and decoder\n","encoder = models.EncoderLSTM(vocab_size=len(lang_train.desc_vocab), hidden_dim=100, num_layers=2, bidir=True, dropout=0.2)\n","decoder = models.DecoderLSTM(vocab_size=len(lang_train.abs_vocab), hidden_dim=100, num_layers=2, bidir=False, dropout=0.2)\n","model = models.Seq2Seq(encoder, decoder)\n","\n","train.train(model=model, train_data=train_data, val_data=val_data, abs_idx2word=lang_train.abs_idx2word, device=device, \n","            batch_size=128, num_epochs=2500, lr=2e-3, print_every_iters=250, tb_descr='dropout-0p2_hiddim-100_numlyrs-2_full-de-vocab-trainsize-512-valsize-16')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["After Iteration 0, Loss is: 9.313465\n","\tModel eval on training data after iteration 0...\n","\t\tRouge-1 is 0.0013, Rouge-2 is 0.0000, and Rouge-l is 0.0045\n","\tModel eval on validation data after iteration 0...\n","\t\tRouge-1 is 0.0013, Rouge-2 is 0.0000, and Rouge-l is 0.0054\n","After Iteration 250, Loss is: 6.959686\n","\tModel eval on training data after iteration 250...\n","\t\tRouge-1 is 0.0564, Rouge-2 is 0.0000, and Rouge-l is 0.0385\n","\tModel eval on validation data after iteration 250...\n","\t\tRouge-1 is 0.0544, Rouge-2 is 0.0000, and Rouge-l is 0.0406\n","After Iteration 500, Loss is: 6.579335\n","\tModel eval on training data after iteration 500...\n","\t\tRouge-1 is 0.0386, Rouge-2 is 0.0000, and Rouge-l is 0.0397\n","\tModel eval on validation data after iteration 500...\n","\t\tRouge-1 is 0.0408, Rouge-2 is 0.0000, and Rouge-l is 0.0313\n","After Iteration 750, Loss is: 5.850194\n","\tModel eval on training data after iteration 750...\n","\t\tRouge-1 is 0.1547, Rouge-2 is 0.0217, and Rouge-l is 0.1933\n","\tModel eval on validation data after iteration 750...\n","\t\tRouge-1 is 0.1608, Rouge-2 is 0.0224, and Rouge-l is 0.1893\n","After Iteration 1000, Loss is: 5.242766\n","\tModel eval on training data after iteration 1000...\n","\t\tRouge-1 is 0.1480, Rouge-2 is 0.0243, and Rouge-l is 0.1691\n","\tModel eval on validation data after iteration 1000...\n","\t\tRouge-1 is 0.1545, Rouge-2 is 0.0247, and Rouge-l is 0.1737\n","After Iteration 1250, Loss is: 4.715829\n","\tModel eval on training data after iteration 1250...\n","\t\tRouge-1 is 0.2212, Rouge-2 is 0.0366, and Rouge-l is 0.2239\n","\tModel eval on validation data after iteration 1250...\n","\t\tRouge-1 is 0.2203, Rouge-2 is 0.0381, and Rouge-l is 0.2292\n","After Iteration 1500, Loss is: 4.156008\n","\tModel eval on training data after iteration 1500...\n","\t\tRouge-1 is 0.2153, Rouge-2 is 0.0389, and Rouge-l is 0.2342\n","\tModel eval on validation data after iteration 1500...\n","\t\tRouge-1 is 0.2273, Rouge-2 is 0.0452, and Rouge-l is 0.2327\n","After Iteration 1750, Loss is: 3.643256\n","\tModel eval on training data after iteration 1750...\n","\t\tRouge-1 is 0.2159, Rouge-2 is 0.0376, and Rouge-l is 0.2262\n","\tModel eval on validation data after iteration 1750...\n","\t\tRouge-1 is 0.2235, Rouge-2 is 0.0398, and Rouge-l is 0.2309\n","After Iteration 2000, Loss is: 3.183571\n","\tModel eval on training data after iteration 2000...\n","\t\tRouge-1 is 0.2290, Rouge-2 is 0.0408, and Rouge-l is 0.2157\n","\tModel eval on validation data after iteration 2000...\n","\t\tRouge-1 is 0.2685, Rouge-2 is 0.0484, and Rouge-l is 0.2284\n","After Iteration 2250, Loss is: 2.750857\n","\tModel eval on training data after iteration 2250...\n","\t\tRouge-1 is 0.2561, Rouge-2 is 0.0433, and Rouge-l is 0.2169\n","\tModel eval on validation data after iteration 2250...\n","\t\tRouge-1 is 0.2537, Rouge-2 is 0.0424, and Rouge-l is 0.2075\n","After Iteration 2500, Loss is: 2.435098\n","\tModel eval on training data after iteration 2500...\n","\t\tRouge-1 is 0.2458, Rouge-2 is 0.0397, and Rouge-l is 0.1956\n","\tModel eval on validation data after iteration 2500...\n","\t\tRouge-1 is 0.2661, Rouge-2 is 0.0403, and Rouge-l is 0.1961\n","After Iteration 2750, Loss is: 2.015852\n","\tModel eval on training data after iteration 2750...\n","\t\tRouge-1 is 0.2556, Rouge-2 is 0.0408, and Rouge-l is 0.2003\n","\tModel eval on validation data after iteration 2750...\n","\t\tRouge-1 is 0.2543, Rouge-2 is 0.0446, and Rouge-l is 0.1909\n","After Iteration 3000, Loss is: 1.864492\n","\tModel eval on training data after iteration 3000...\n","\t\tRouge-1 is 0.2610, Rouge-2 is 0.0389, and Rouge-l is 0.2010\n","\tModel eval on validation data after iteration 3000...\n","\t\tRouge-1 is 0.2568, Rouge-2 is 0.0396, and Rouge-l is 0.1869\n","After Iteration 3250, Loss is: 1.692243\n","\tModel eval on training data after iteration 3250...\n","\t\tRouge-1 is 0.2635, Rouge-2 is 0.0376, and Rouge-l is 0.1926\n","\tModel eval on validation data after iteration 3250...\n","\t\tRouge-1 is 0.2550, Rouge-2 is 0.0300, and Rouge-l is 0.1876\n","After Iteration 3500, Loss is: 1.626757\n","\tModel eval on training data after iteration 3500...\n","\t\tRouge-1 is 0.2623, Rouge-2 is 0.0399, and Rouge-l is 0.1858\n","\tModel eval on validation data after iteration 3500...\n","\t\tRouge-1 is 0.2677, Rouge-2 is 0.0372, and Rouge-l is 0.1995\n","After Iteration 3750, Loss is: 1.447882\n","\tModel eval on training data after iteration 3750...\n","\t\tRouge-1 is 0.2567, Rouge-2 is 0.0386, and Rouge-l is 0.1956\n","\tModel eval on validation data after iteration 3750...\n","\t\tRouge-1 is 0.2529, Rouge-2 is 0.0379, and Rouge-l is 0.1816\n","After Iteration 4000, Loss is: 1.340369\n","\tModel eval on training data after iteration 4000...\n","\t\tRouge-1 is 0.2530, Rouge-2 is 0.0338, and Rouge-l is 0.1851\n","\tModel eval on validation data after iteration 4000...\n","\t\tRouge-1 is 0.2574, Rouge-2 is 0.0337, and Rouge-l is 0.1650\n","After Iteration 4250, Loss is: 1.198083\n","\tModel eval on training data after iteration 4250...\n","\t\tRouge-1 is 0.2522, Rouge-2 is 0.0377, and Rouge-l is 0.1868\n","\tModel eval on validation data after iteration 4250...\n","\t\tRouge-1 is 0.2526, Rouge-2 is 0.0356, and Rouge-l is 0.1743\n","After Iteration 4500, Loss is: 1.178302\n","\tModel eval on training data after iteration 4500...\n","\t\tRouge-1 is 0.2546, Rouge-2 is 0.0355, and Rouge-l is 0.1812\n","\tModel eval on validation data after iteration 4500...\n","\t\tRouge-1 is 0.2544, Rouge-2 is 0.0283, and Rouge-l is 0.1695\n","After Iteration 4750, Loss is: 1.132705\n","\tModel eval on training data after iteration 4750...\n","\t\tRouge-1 is 0.2494, Rouge-2 is 0.0359, and Rouge-l is 0.1837\n","\tModel eval on validation data after iteration 4750...\n","\t\tRouge-1 is 0.2367, Rouge-2 is 0.0316, and Rouge-l is 0.1634\n","After Iteration 5000, Loss is: 1.092822\n","\tModel eval on training data after iteration 5000...\n","\t\tRouge-1 is 0.2592, Rouge-2 is 0.0377, and Rouge-l is 0.1873\n","\tModel eval on validation data after iteration 5000...\n","\t\tRouge-1 is 0.2652, Rouge-2 is 0.0320, and Rouge-l is 0.1838\n","After Iteration 5250, Loss is: 0.998983\n","\tModel eval on training data after iteration 5250...\n","\t\tRouge-1 is 0.2557, Rouge-2 is 0.0352, and Rouge-l is 0.1854\n","\tModel eval on validation data after iteration 5250...\n","\t\tRouge-1 is 0.2664, Rouge-2 is 0.0338, and Rouge-l is 0.1738\n","After Iteration 5500, Loss is: 0.940292\n","\tModel eval on training data after iteration 5500...\n","\t\tRouge-1 is 0.2555, Rouge-2 is 0.0353, and Rouge-l is 0.1764\n","\tModel eval on validation data after iteration 5500...\n","\t\tRouge-1 is 0.2638, Rouge-2 is 0.0389, and Rouge-l is 0.1815\n","After Iteration 5750, Loss is: 0.879838\n","\tModel eval on training data after iteration 5750...\n","\t\tRouge-1 is 0.2640, Rouge-2 is 0.0359, and Rouge-l is 0.1787\n","\tModel eval on validation data after iteration 5750...\n","\t\tRouge-1 is 0.2391, Rouge-2 is 0.0279, and Rouge-l is 0.1623\n","After Iteration 6000, Loss is: 0.804977\n","\tModel eval on training data after iteration 6000...\n","\t\tRouge-1 is 0.2513, Rouge-2 is 0.0338, and Rouge-l is 0.1786\n","\tModel eval on validation data after iteration 6000...\n","\t\tRouge-1 is 0.2382, Rouge-2 is 0.0274, and Rouge-l is 0.1645\n","After Iteration 6250, Loss is: 0.842113\n","\tModel eval on training data after iteration 6250...\n","\t\tRouge-1 is 0.2657, Rouge-2 is 0.0350, and Rouge-l is 0.1799\n","\tModel eval on validation data after iteration 6250...\n","\t\tRouge-1 is 0.2411, Rouge-2 is 0.0276, and Rouge-l is 0.1621\n","After Iteration 6500, Loss is: 0.759964\n","\tModel eval on training data after iteration 6500...\n","\t\tRouge-1 is 0.2540, Rouge-2 is 0.0359, and Rouge-l is 0.1800\n","\tModel eval on validation data after iteration 6500...\n","\t\tRouge-1 is 0.2701, Rouge-2 is 0.0315, and Rouge-l is 0.1856\n","After Iteration 6750, Loss is: 0.708117\n","\tModel eval on training data after iteration 6750...\n","\t\tRouge-1 is 0.2571, Rouge-2 is 0.0348, and Rouge-l is 0.1809\n","\tModel eval on validation data after iteration 6750...\n","\t\tRouge-1 is 0.2183, Rouge-2 is 0.0216, and Rouge-l is 0.1557\n","After Iteration 7000, Loss is: 0.730687\n","\tModel eval on training data after iteration 7000...\n","\t\tRouge-1 is 0.2567, Rouge-2 is 0.0348, and Rouge-l is 0.1834\n","\tModel eval on validation data after iteration 7000...\n","\t\tRouge-1 is 0.2234, Rouge-2 is 0.0294, and Rouge-l is 0.1510\n","After Iteration 7250, Loss is: 0.697542\n","\tModel eval on training data after iteration 7250...\n","\t\tRouge-1 is 0.2581, Rouge-2 is 0.0363, and Rouge-l is 0.1781\n","\tModel eval on validation data after iteration 7250...\n","\t\tRouge-1 is 0.2385, Rouge-2 is 0.0238, and Rouge-l is 0.1727\n","After Iteration 7500, Loss is: 0.622789\n","\tModel eval on training data after iteration 7500...\n","\t\tRouge-1 is 0.2559, Rouge-2 is 0.0320, and Rouge-l is 0.1829\n","\tModel eval on validation data after iteration 7500...\n","\t\tRouge-1 is 0.2369, Rouge-2 is 0.0172, and Rouge-l is 0.1759\n","After Iteration 7750, Loss is: 0.600940\n","\tModel eval on training data after iteration 7750...\n","\t\tRouge-1 is 0.2451, Rouge-2 is 0.0300, and Rouge-l is 0.1776\n","\tModel eval on validation data after iteration 7750...\n","\t\tRouge-1 is 0.2733, Rouge-2 is 0.0324, and Rouge-l is 0.1840\n","After Iteration 8000, Loss is: 0.598587\n","\tModel eval on training data after iteration 8000...\n","\t\tRouge-1 is 0.2491, Rouge-2 is 0.0299, and Rouge-l is 0.1762\n","\tModel eval on validation data after iteration 8000...\n","\t\tRouge-1 is 0.2626, Rouge-2 is 0.0320, and Rouge-l is 0.1782\n","After Iteration 8250, Loss is: 0.570664\n","\tModel eval on training data after iteration 8250...\n","\t\tRouge-1 is 0.2538, Rouge-2 is 0.0343, and Rouge-l is 0.1797\n","\tModel eval on validation data after iteration 8250...\n","\t\tRouge-1 is 0.2585, Rouge-2 is 0.0382, and Rouge-l is 0.1813\n","After Iteration 8500, Loss is: 0.546578\n","\tModel eval on training data after iteration 8500...\n","\t\tRouge-1 is 0.2535, Rouge-2 is 0.0318, and Rouge-l is 0.1760\n","\tModel eval on validation data after iteration 8500...\n","\t\tRouge-1 is 0.2487, Rouge-2 is 0.0322, and Rouge-l is 0.1719\n","After Iteration 8750, Loss is: 0.517167\n","\tModel eval on training data after iteration 8750...\n","\t\tRouge-1 is 0.2495, Rouge-2 is 0.0317, and Rouge-l is 0.1762\n","\tModel eval on validation data after iteration 8750...\n","\t\tRouge-1 is 0.2428, Rouge-2 is 0.0348, and Rouge-l is 0.1683\n","After Iteration 9000, Loss is: 0.495741\n","\tModel eval on training data after iteration 9000...\n","\t\tRouge-1 is 0.2534, Rouge-2 is 0.0332, and Rouge-l is 0.1811\n","\tModel eval on validation data after iteration 9000...\n","\t\tRouge-1 is 0.2266, Rouge-2 is 0.0226, and Rouge-l is 0.1875\n","After Iteration 9250, Loss is: 0.513205\n","\tModel eval on training data after iteration 9250...\n","\t\tRouge-1 is 0.2582, Rouge-2 is 0.0314, and Rouge-l is 0.1818\n","\tModel eval on validation data after iteration 9250...\n","\t\tRouge-1 is 0.2624, Rouge-2 is 0.0328, and Rouge-l is 0.1702\n","After Iteration 9500, Loss is: 0.427750\n","\tModel eval on training data after iteration 9500...\n","\t\tRouge-1 is 0.2483, Rouge-2 is 0.0307, and Rouge-l is 0.1786\n","\tModel eval on validation data after iteration 9500...\n","\t\tRouge-1 is 0.2653, Rouge-2 is 0.0356, and Rouge-l is 0.1732\n","After Iteration 9750, Loss is: 0.434375\n","\tModel eval on training data after iteration 9750...\n","\t\tRouge-1 is 0.2651, Rouge-2 is 0.0371, and Rouge-l is 0.1810\n","\tModel eval on validation data after iteration 9750...\n","\t\tRouge-1 is 0.2393, Rouge-2 is 0.0279, and Rouge-l is 0.1710\n","\n","Model eval on validation data after final iteration...\n","Example\n","Prediction\n","a method for transporting gravel to a production zone with a circulating well fluid to uniformly pack the gravel in the machine of the building surface of the casing hanger to contact a --oov-- , . the exercising element is attached to the toilet has a window formation . a maximum bag in a spring body engages a lip in the rotation of the tool during use of undesired shear panels reduces the --oov-- outwardly , collapse of the electromagnet in the configuration of the roller on the well equipment and the structure . --stop--                                                                                \n","Target\n","a self - --oov-- --oov-- with skirt construction for attack tools including a --oov-- which replaces a conventional cutting element on the tip of the work engaging end of the tool to provide improved longevity and cutting characteristics and produce less dust , and a skirt which --oov-- portions of the side of the work engaging end of the tool and the --oov-- to support the --oov-- and to prevent the erosion of the tool and the --oov-- and loss of the --oov-- , the present --oov-- and skirt construction being adapted for use with attack tools for mining , excavating , removing highway road surfaces and the like , and optionally including a layer of a super hard material on the outer surfaces thereof to provide even greater --oov-- and durability . --stop--               \n","Rouge-1 is 0.2624, Rouge-2 is 0.0364, and Rouge-l is 0.1863\n","1 loop, best of 1: 3h 19min 57s per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4vokLQMdJOKG"},"source":["Training Loss |Training Data Rouge | Validation Data Rouge\n","--- | --- | ---\n","![](https://drive.google.com/uc?export=view&id=1Hy_uPwJqZeXkGS8yMop4hh8EPXouBBs8) | ![](https://drive.google.com/uc?export=view&id=16pGdDmWSNT20jhBXsYNomIdgQQetDPwT) | ![](https://drive.google.com/uc?export=view&id=1-Aq6-lTs0fJ6_FopLEQC-G1suURPtTZc)\n","| Orange: Rouge-1, Blue: Rouge-2, Dark Orange: Rouge-l | Light Blue: Rouge-1, Pink: Rouge-2, Teal: Rouge-l"]},{"cell_type":"code","metadata":{"id":"qlbDYtLnUDwz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TLONE3x1rXas"},"source":["Note that the initial loss will be approximately -log(abstract_vocab_size) because the model is randomly initialized."]},{"cell_type":"markdown","metadata":{"id":"a1SXmgbVMeEo"},"source":["## Visualization Using Tensorboard"]},{"cell_type":"code","metadata":{"id":"1sBZZ2Dn-mXL"},"source":["%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ivc8PTXYfbGn"},"source":["%tensorboard --logdir='runs'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MdVp4UCSUfGb"},"source":["## Future Experimentation\n","1. Use glove embeddings to initialize the embeddings layer\n","2. for decoder use initial value of h and c from encoder output or just h and initialize c with zero?\n","3. see if can get rid of stop token from the decription\n","4. use weight in the cross entropy loss proportional to the word counts in the abstract vocabulary\n","5. Use beam search\n","6. add attention and make model larger (more lstm layers and increase hidden dim size)\n","7. use transformers\n","8. use teacher forcing only 50% of the time when training and not 100%\n","9. use some of the ideas documented as part of my literature survey\n","10. Use command line arguments when calling python script\n","11. Other ideas to try:\n","- http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/\n","- https://towardsdatascience.com/abstractive-summarization-of-dialogues-f530c7d290be\n","- https://www.analyticsvidhya.com/blog/2021/02/dialogue-summarization-a-deep-learning-approach/\n","- https://www.analyticsvidhya.com/blog/2020/11/summarize-twitter-live-data-using-pretrained-nlp-models/"]},{"cell_type":"code","metadata":{"id":"_Z574Y5Vd3Eh"},"source":[""],"execution_count":null,"outputs":[]}]}