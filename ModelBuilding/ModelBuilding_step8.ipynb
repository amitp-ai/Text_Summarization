{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ModelBuilding_step8.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNdrF4SxRjj6jm/4cVRJcnm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"52AVLV-QKUHY"},"source":["# Model Building\n","\n","In this notebook we will build with different deep learning based models for text summarization. In particular, the architecture used here is an encoder-decoder type of network built using LSTM layers. Refer to the literature review notebook for further details on this architecture.\n","\n","In this notebook we will experiment with various settings such as number of hidden dimensions, dropout, size of training data vocabulary, number of LSTM layers, etc.\n","\n","We will use Pytorch to train the models and Tensorboard (integrated with Pytorch) for visualization."]},{"cell_type":"markdown","metadata":{"id":"8ej8yLC6KbIz"},"source":["## Mount Google Drive and Import Libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8BlEalhJt6O","executionInfo":{"status":"ok","timestamp":1618847057433,"user_tz":420,"elapsed":295,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"57837903-a1b3-4183-dc40-3747eb1163bb"},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kN_j2lJNKABX","executionInfo":{"status":"ok","timestamp":1618847063475,"user_tz":420,"elapsed":5341,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"eed161c8-197e-4b13-ee6b-b7a7f70c40ca"},"source":["import sys\n","import os\n","import torch\n","# for auto-reloading external modules (automatically reloads before using an imported module)\n","%load_ext autoreload\n","%autoreload 2\n","\n","#To ensure that the Colab Python interpreter can load Python files from within\n","PATH_NAME = os.path.join('/', 'content', 'drive', 'My Drive', 'Colab Notebooks', 'UCSDX_MLE_Bootcamp', 'Text_Summarization_UCSD', 'ModelBuilding')\n","sys.path.append(os.path.join(PATH_NAME, 'src'))\n","print(sys.path)\n","%cd $PATH_NAME\n","\n","print(f'Torch version {torch.__version__}') #1.8.1+cu101"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/My Drive/Colab Notebooks/UCSDX_MLE_Bootcamp/Text_Summarization_UCSD/ModelBuilding/src']\n","/content/drive/My Drive/Colab Notebooks/UCSDX_MLE_Bootcamp/Text_Summarization_UCSD/ModelBuilding\n","Torch version 1.8.1+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fF-AH2CUARB-"},"source":["!git config --global user.name “[Amit Patel]”\n","!git config --global user.email “[amitpatel.gt@gmail.com]”\n","!git config --global color.ui auto\n","!git config -l\n","\n","!git add .\n","!git commit -m \"Added LSTM with attention model\"\n","!git status"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bFrNrAmAClX0","executionInfo":{"status":"ok","timestamp":1618868219881,"user_tz":420,"elapsed":436,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"b5b8bfde-1413-4942-d803-07c33470cb54"},"source":[""],"execution_count":16,"outputs":[{"output_type":"stream","text":["images\tModelBuilding_step8.ipynb\t\t  __pycache__  saved_models\n","logs\tModel_Experimentation_step7_14-8-1.ipynb  runs\t       src\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sASbLseT2nA","executionInfo":{"status":"ok","timestamp":1618847064581,"user_tz":420,"elapsed":451,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"6e8bf334-b882-4b35-cca8-8a748372e08a"},"source":["!nvidia-smi"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mon Apr 19 15:44:24 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B764-g_HOmrX"},"source":["## Load Data and Utility Functions\n","We will use cpc_codes 'de' from the BigPatent dataset"]},{"cell_type":"code","metadata":{"id":"URPZY5SHP2Rh","executionInfo":{"status":"ok","timestamp":1618847069069,"user_tz":420,"elapsed":300,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}}},"source":[""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVoKY6IiLYrM","executionInfo":{"status":"ok","timestamp":1618847070196,"user_tz":420,"elapsed":473,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}}},"source":["'''\n","import utils\n","data = utils.load_data_numpy(split_type='train', cpc_codes='de', fname='data0_np.npz')\n","for data_np in data:\n","    print(data_np['data'].shape, data_np['data'][0,0].shape[1], data_np['data'][0,1].shape[1])\n","    print(data_np['data'][0,1])\n","    break\n","del data, data_np\n","''';"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ar2PdtvzfZ8r"},"source":["### Mini Data: Generate vocabulary, word2idx, idx2word, and numpy array\n","\n","Need to do this as the vocabulary for the full dataset is too large for quick prototying and debugging.\n","\n","But try with both, the full vocabulary for the de dataset as well as the vocabulary created from the mini training set."]},{"cell_type":"code","metadata":{"id":"fqZwzx7sz_kc","executionInfo":{"status":"ok","timestamp":1618847072294,"user_tz":420,"elapsed":1111,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}}},"source":[""],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2E_aYv_utK96"},"source":["## LSTM Based Encoder-Decoder\n","\n","For further details:-\n","\n","https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\n","\n"," http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IYheFFte0gus","executionInfo":{"status":"ok","timestamp":1618847077692,"user_tz":420,"elapsed":4430,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"eca36f6c-00f2-4fd2-e04b-a932f80286fc"},"source":["!pip install rouge"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting rouge\n","  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WWZP3hElL1-7","executionInfo":{"status":"ok","timestamp":1618847079089,"user_tz":420,"elapsed":233,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}}},"source":[""],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"As_oDnGXVbGT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618847264151,"user_tz":420,"elapsed":2352,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"a8f6c1cc-97e9-434d-c553-5a1461b79f3c"},"source":["#testing\n","!python -m pytest -s ../tests/"],"execution_count":9,"outputs":[{"output_type":"stream","text":["\u001b[1m============================= test session starts ==============================\u001b[0m\n","platform linux -- Python 3.7.10, pytest-3.6.4, py-1.10.0, pluggy-0.7.1\n","rootdir: /content/drive/My Drive/Colab Notebooks/UCSDX_MLE_Bootcamp/Text_Summarization_UCSD, inifile:\n","plugins: typeguard-2.7.1\n","collected 3 items                                                              \u001b[0m\n","\n","../tests/test_ModelBuilding1.py ...\n","\n","\u001b[32m\u001b[1m=========================== 3 passed in 1.26 seconds ===========================\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7MBYSR8Onw_v"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ehz70x7doXmr"},"source":["#### Seq2Seq: lr=0.004, dropout=0.0, hiddim=200, numlyrs=2, full-de-vocab, train_size=128, val_size=16"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmHxAh_XHdlq","executionInfo":{"status":"ok","timestamp":1618619277586,"user_tz":420,"elapsed":1543886,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"438b82cd-8efd-4df1-8c43-c21d69d732c8"},"source":["%%timeit -r 1 -n 1\n","#test above trained model with beamsize=5 \n","!python ./src/train.py --hiddenDim 200 --numLayers 2 --batchSize 64 --numEpochs 700 --lr 2e-3 --savedModelDir './saved_models/seq2seq_200hid_2lyrs' \\\n","                        --printEveryIters 4800 --tbDescr 'dropout-0_hiddim-200_numlyrs-2_full-de-data' \\\n","                        --modelType 'models.Seq2Seq' --loadBestModel False --toTrain True\n","#but there is no improvement in rouge scores vs no beam search (greedy search seems to be ok for a well trained model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Getting the training data...\n","Size of description vocab is 36828 and abstract vocab is 10769\n","tcmalloc: large alloc 2406391808 bytes == 0x55912d3c0000 @  0x7fb2f175c1e7 0x5590b2ec0f48 0x7fb2c82ce53e 0x7fb2c82cecd9 0x7fb2c82cefaf 0x7fb2c82cc4b4 0x5590b2e8f0e4 0x5590b2e8ede0 0x5590b2f036f5 0x5590b2e9069a 0x5590b2efec9e 0x5590b2e9069a 0x5590b2efec9e 0x5590b2e9069a 0x5590b2efec9e 0x5590b2e9069a 0x5590b2efec9e 0x5590b2efdb0e 0x5590b2dcfe2b 0x5590b2f001e6 0x5590b2efde0d 0x5590b2dcfe2b 0x5590b2f001e6 0x5590b2efde0d 0x5590b2e9077a 0x5590b2eff86a 0x5590b2f81858 0x5590b2efeee2 0x5590b2efdb0e 0x5590b2e9077a 0x5590b2eff86a\n","max length (before adding stop token) in mini_df.description is 3943 and in mini_df.abstract (before adding start/stop tokens) is 147\n","(128, 4)\n","max length (before adding stop token) in mini_df.description is 3993 and in mini_df.abstract (before adding start/stop tokens) is 140\n","(16, 4)\n","Data shape is: torch.Size([128, 4000]), torch.Size([128, 150]), torch.Size([128])\n","Total data size is: 2.125MB\n","Data shape is: torch.Size([16, 4000]), torch.Size([16, 150]), torch.Size([16])\n","\n","Starting model training...\n","Namespace(batchSize=64, hiddenDim=200, loadBestModel=False, lr=0.002, modelType='models.Seq2Seq', numEpochs=700, numLayers=2, printEveryIters=4800, savedModelDir='./saved_models/seq2seq_200hid_2lyrs', seed=0, tbDescr='dropout-0_hiddim-200_numlyrs-2_full-de-data')\n","2021-04-17 00:02:29.783872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","Saver will maximize rouge-1...\n","After Iteration 4800, Loss is: 6.955113\n","\tModel eval on training data after iteration 4800...\n","\t\tRouge-1 is 0.0639, Rouge-2 is 0.0000, and Rouge-l is 0.0760\n","\tModel eval on validation data after iteration 4800...\n","\t\tRouge-1 is 0.0658, Rouge-2 is 0.0000, and Rouge-l is 0.0704\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_4800.pth.tar\n","New best checkpoint at step 4800...\n","After Iteration 9600, Loss is: 7.001317\n","\tModel eval on training data after iteration 9600...\n","\t\tRouge-1 is 0.0947, Rouge-2 is 0.0000, and Rouge-l is 0.0727\n","\tModel eval on validation data after iteration 9600...\n","\t\tRouge-1 is 0.0952, Rouge-2 is 0.0000, and Rouge-l is 0.0704\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_9600.pth.tar\n","New best checkpoint at step 9600...\n","After Iteration 14400, Loss is: 6.633576\n","\tModel eval on training data after iteration 14400...\n","\t\tRouge-1 is 0.0943, Rouge-2 is 0.0000, and Rouge-l is 0.0709\n","\tModel eval on validation data after iteration 14400...\n","\t\tRouge-1 is 0.0952, Rouge-2 is 0.0000, and Rouge-l is 0.0704\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_14400.pth.tar\n","New best checkpoint at step 14400...\n","After Iteration 19200, Loss is: 6.437768\n","\tModel eval on training data after iteration 19200...\n","\t\tRouge-1 is 0.1851, Rouge-2 is 0.0226, and Rouge-l is 0.1527\n","\tModel eval on validation data after iteration 19200...\n","\t\tRouge-1 is 0.1880, Rouge-2 is 0.0247, and Rouge-l is 0.1331\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_19200.pth.tar\n","New best checkpoint at step 19200...\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_4800.pth.tar\n","After Iteration 24000, Loss is: 6.242340\n","\tModel eval on training data after iteration 24000...\n","\t\tRouge-1 is 0.1820, Rouge-2 is 0.0222, and Rouge-l is 0.1516\n","\tModel eval on validation data after iteration 24000...\n","\t\tRouge-1 is 0.1847, Rouge-2 is 0.0251, and Rouge-l is 0.1331\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_24000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_9600.pth.tar\n","After Iteration 28800, Loss is: 6.041616\n","\tModel eval on training data after iteration 28800...\n","\t\tRouge-1 is 0.2005, Rouge-2 is 0.0268, and Rouge-l is 0.1687\n","\tModel eval on validation data after iteration 28800...\n","\t\tRouge-1 is 0.1978, Rouge-2 is 0.0300, and Rouge-l is 0.1649\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_28800.pth.tar\n","New best checkpoint at step 28800...\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_14400.pth.tar\n","After Iteration 33600, Loss is: 5.804053\n","\tModel eval on training data after iteration 33600...\n","\t\tRouge-1 is 0.1539, Rouge-2 is 0.0230, and Rouge-l is 0.1779\n","\tModel eval on validation data after iteration 33600...\n","\t\tRouge-1 is 0.1621, Rouge-2 is 0.0248, and Rouge-l is 0.1751\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_33600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_33600.pth.tar\n","After Iteration 38400, Loss is: 5.655819\n","\tModel eval on training data after iteration 38400...\n","\t\tRouge-1 is 0.1860, Rouge-2 is 0.0308, and Rouge-l is 0.2095\n","\tModel eval on validation data after iteration 38400...\n","\t\tRouge-1 is 0.1923, Rouge-2 is 0.0365, and Rouge-l is 0.2069\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_38400.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_24000.pth.tar\n","After Iteration 43200, Loss is: 5.447897\n","\tModel eval on training data after iteration 43200...\n","\t\tRouge-1 is 0.2120, Rouge-2 is 0.0198, and Rouge-l is 0.2070\n","\tModel eval on validation data after iteration 43200...\n","\t\tRouge-1 is 0.2155, Rouge-2 is 0.0243, and Rouge-l is 0.2057\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_43200.pth.tar\n","New best checkpoint at step 43200...\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_19200.pth.tar\n","After Iteration 48000, Loss is: 5.237099\n","\tModel eval on training data after iteration 48000...\n","\t\tRouge-1 is 0.2702, Rouge-2 is 0.0411, and Rouge-l is 0.2373\n","\tModel eval on validation data after iteration 48000...\n","\t\tRouge-1 is 0.2696, Rouge-2 is 0.0418, and Rouge-l is 0.2263\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_48000.pth.tar\n","New best checkpoint at step 48000...\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_38400.pth.tar\n","After Iteration 52800, Loss is: 4.933527\n","\tModel eval on training data after iteration 52800...\n","\t\tRouge-1 is 0.2662, Rouge-2 is 0.0388, and Rouge-l is 0.2229\n","\tModel eval on validation data after iteration 52800...\n","\t\tRouge-1 is 0.2815, Rouge-2 is 0.0469, and Rouge-l is 0.2304\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_52800.pth.tar\n","New best checkpoint at step 52800...\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_28800.pth.tar\n","After Iteration 57600, Loss is: 4.676332\n","\tModel eval on training data after iteration 57600...\n","\t\tRouge-1 is 0.2840, Rouge-2 is 0.0511, and Rouge-l is 0.2351\n","\tModel eval on validation data after iteration 57600...\n","\t\tRouge-1 is 0.2855, Rouge-2 is 0.0486, and Rouge-l is 0.2373\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_57600.pth.tar\n","New best checkpoint at step 57600...\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_43200.pth.tar\n","After Iteration 62400, Loss is: 4.476898\n","\tModel eval on training data after iteration 62400...\n","\t\tRouge-1 is 0.2387, Rouge-2 is 0.0457, and Rouge-l is 0.2149\n","\tModel eval on validation data after iteration 62400...\n","\t\tRouge-1 is 0.2503, Rouge-2 is 0.0478, and Rouge-l is 0.2133\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_62400.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_62400.pth.tar\n","After Iteration 67200, Loss is: 4.168442\n","\tModel eval on training data after iteration 67200...\n","\t\tRouge-1 is 0.2897, Rouge-2 is 0.0462, and Rouge-l is 0.2419\n","\tModel eval on validation data after iteration 67200...\n","\t\tRouge-1 is 0.2893, Rouge-2 is 0.0430, and Rouge-l is 0.2302\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_67200.pth.tar\n","New best checkpoint at step 67200...\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_48000.pth.tar\n","After Iteration 72000, Loss is: 3.969476\n","\tModel eval on training data after iteration 72000...\n","\t\tRouge-1 is 0.2753, Rouge-2 is 0.0486, and Rouge-l is 0.2284\n","\tModel eval on validation data after iteration 72000...\n","\t\tRouge-1 is 0.2772, Rouge-2 is 0.0488, and Rouge-l is 0.2180\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_72000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_72000.pth.tar\n","After Iteration 76800, Loss is: 3.703367\n","\tModel eval on training data after iteration 76800...\n","\t\tRouge-1 is 0.2858, Rouge-2 is 0.0569, and Rouge-l is 0.1983\n","\tModel eval on validation data after iteration 76800...\n","\t\tRouge-1 is 0.2723, Rouge-2 is 0.0467, and Rouge-l is 0.1980\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_76800.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_76800.pth.tar\n","After Iteration 81600, Loss is: 3.386537\n","\tModel eval on training data after iteration 81600...\n","\t\tRouge-1 is 0.2870, Rouge-2 is 0.0508, and Rouge-l is 0.1963\n","\tModel eval on validation data after iteration 81600...\n","\t\tRouge-1 is 0.2781, Rouge-2 is 0.0444, and Rouge-l is 0.1821\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_81600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_81600.pth.tar\n","After Iteration 86400, Loss is: 3.014953\n","\tModel eval on training data after iteration 86400...\n","\t\tRouge-1 is 0.2811, Rouge-2 is 0.0478, and Rouge-l is 0.1944\n","\tModel eval on validation data after iteration 86400...\n","\t\tRouge-1 is 0.2784, Rouge-2 is 0.0399, and Rouge-l is 0.1893\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_86400.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_86400.pth.tar\n","\n","Model eval on validation data after final iteration...\n","Example\n","Prediction\n","a method of producing a durable device for re - type joining a pretreatment on fabrics , and a base of the first of porous material to improve performance , and hydrogen peroxide and mixtures of which is located on the sliding frame and second off and a base blocks to be forcibly compressed to crimp or frictionally engage the base of the second of which is provided , and the block and and the block is attempted to brace the surface of a first layer motor by a central bore of a first layer motor by a central bore of a first layer position . the locking member . --stop--\n","Target\n","an apparatus for manipulating an eccentrically located well bore device is disclosed . one embodiment of the apparatus comprises : a main body attachable to a conveyance member ; an arm hinged to the main body ; a lock assembly for selectively retaining the arm in a locked position and releasing the arm from the locked position ; a kick over assembly for moving the arm to a --oov-- over position ; and an adapter connected to the lift arm , the adapter connectable with a tool for latching onto the device . the kick over assembly comprises a kick member operatively connected to the arm and a biasing member having\n","For this example, Rouge-1 is 0.2686, Rouge-2 is 0.0342, and Rouge-l is 0.1801\n","\n","\tRouge-1 is 0.2686, Rouge-2 is 0.0342, and Rouge-l is 0.1801\n","Saved checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_89600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_200hid_2lyrs/step_89600.pth.tar\n","1 loop, best of 1: 25min 42s per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"diEaeZ3FqMhK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618714368080,"user_tz":420,"elapsed":20520,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"a3611cbc-96c2-4723-a557-de62f014085a"},"source":["%%timeit -r 1 -n 1\n","#without attention\n","#test above trained model with beamsize=5 \n","!python ./src/train.py --hiddenDim 200 --numLayers 2 --batchSize 64 --numEpochs 700 --lr 2e-3 --savedModelDir './saved_models/seq2seq_200hid_2lyrs' \\\n","                        --printEveryIters 4800 --tbDescr 'dropout-0_hiddim-200_numlyrs-2_full-de-data' \\\n","                        --modelType 'models.Seq2Seq' --loadBestModel True --toTrain False\n","#but there is no improvement in rouge scores vs no beam search (greedy search seems to be ok for a well trained model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Getting the training data...\n","Size of description vocab is 36828 and abstract vocab is 10769\n","tcmalloc: large alloc 2406391808 bytes == 0x559e320c8000 @  0x7f5b4fc221e7 0x559db70f0f48 0x7f5b2679453e 0x7f5b26794cd9 0x7f5b26794faf 0x7f5b267924b4 0x559db70bf0e4 0x559db70bede0 0x559db71336f5 0x559db70c069a 0x559db712ec9e 0x559db70c069a 0x559db712ec9e 0x559db70c069a 0x559db712ec9e 0x559db70c069a 0x559db712ec9e 0x559db712db0e 0x559db6fffe2b 0x559db71301e6 0x559db712de0d 0x559db6fffe2b 0x559db71301e6 0x559db712de0d 0x559db70c077a 0x559db712f86a 0x559db71b1858 0x559db712eee2 0x559db712db0e 0x559db70c077a 0x559db712f86a\n","max length (before adding stop token) in mini_df.description is 3943 and in mini_df.abstract (before adding start/stop tokens) is 147\n","(128, 4)\n","max length (before adding stop token) in mini_df.description is 3993 and in mini_df.abstract (before adding start/stop tokens) is 140\n","(16, 4)\n","Data shape is: torch.Size([128, 4000]), torch.Size([128, 150]), torch.Size([128])\n","Total data size is: 2.125MB\n","Data shape is: torch.Size([16, 4000]), torch.Size([16, 150]), torch.Size([16])\n","Loaded the current best model for Seq2Seq, which is from step 67200 and metric value is 0.289\n","Starting model evaluation for the current best model...\n","Namespace(batchSize=64, hiddenDim=200, loadBestModel=True, lr=0.002, modelType='models.Seq2Seq', numEpochs=700, numLayers=2, printEveryIters=4800, savedModelDir='./saved_models/seq2seq_200hid_2lyrs', seed=0, tbDescr='dropout-0_hiddim-200_numlyrs-2_full-de-data', toTrain=False)\n","\tModel eval on validation data...\n","Example\n","Prediction\n","a method for producing the tool is disclosed for a --oov-- with a base , a base , a plurality of steps of the --oov-- , and a plurality of more or more or a --oov-- . the --oov-- , and / or or other with a second element and a second element and to the base , a second element and / or . the base and a second layer . the base and a second layer . the --oov-- . --stop--\n","Target\n","apparatus for processing low - grade collected waste paper . short , so - called zero fibers , which form up to --#number#-- percent of the whole material , and which substantially reduce the quality of paper manufactured therewith are removed , and the bonding properties of the long fiber fraction are removed . it is possible by use of the apparatus to process to paper of good quality from collected low - grade waste paper without previous manual separation of different kinds\n","For this example, Rouge-1 is 0.2893, Rouge-2 is 0.0430, and Rouge-l is 0.2302\n","\n","Rouge-1 is 0.2893, Rouge-2 is 0.0430, and Rouge-l is 0.2302\n","1 loop, best of 1: 20.2 s per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_aoNKp62pghY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lNjY0SHuLWIj"},"source":["#### Seq2Seq with Atten: lr=0.004, dropout=0.1, hiddim=200, numlyrs=2, full-de-vocab, train_size=128, val_size=16"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPxyO93OAenh","executionInfo":{"status":"ok","timestamp":1618775154755,"user_tz":420,"elapsed":7120399,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"bb345228-e308-49c3-fd82-8127264179cd"},"source":["%%timeit -r 1 -n 1\n","#with attention\n","!python ./src/train.py --hiddenDim 200 --numLayers 2 --batchSize 64 --numEpochs 3000 --lr 4e-3 --savedModelDir './saved_models/seq2seq_withAtten_200hid_2lyrs' \\\n","                        --printEveryIters 400 --tbDescr 'seq2seq_withAtten_dropout-0p1_hiddim-200_numlyrs-2_full-de-vocab' \\\n","                        --modelType 'models.Seq2SeqwithAttention' --loadBestModel False --toTrain True \\\n","                        --dropout 0.1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Getting the training data...\n","Size of description vocab is 36828 and abstract vocab is 10769\n","tcmalloc: large alloc 2406391808 bytes == 0x558ffe044000 @  0x7fec669a51e7 0x558f8340ff48 0x7fec3d51753e 0x7fec3d517cd9 0x7fec3d517faf 0x7fec3d5154b4 0x558f833de0e4 0x558f833ddde0 0x558f834526f5 0x558f833df69a 0x558f8344dc9e 0x558f833df69a 0x558f8344dc9e 0x558f833df69a 0x558f8344dc9e 0x558f833df69a 0x558f8344dc9e 0x558f8344cb0e 0x558f8331ee2b 0x558f8344f1e6 0x558f8344ce0d 0x558f8331ee2b 0x558f8344f1e6 0x558f8344ce0d 0x558f833df77a 0x558f8344e86a 0x558f834d0858 0x558f8344dee2 0x558f8344cb0e 0x558f833df77a 0x558f8344e86a\n","max length (before adding stop token) in mini_df.description is 3943 and in mini_df.abstract (before adding start/stop tokens) is 147\n","(128, 4)\n","max length (before adding stop token) in mini_df.description is 3993 and in mini_df.abstract (before adding start/stop tokens) is 140\n","(16, 4)\n","Data shape is: torch.Size([128, 4000]), torch.Size([128, 150]), torch.Size([128])\n","Total data size is: 2.125MB\n","Data shape is: torch.Size([16, 4000]), torch.Size([16, 150]), torch.Size([16])\n","\n","Starting model training...\n","Namespace(batchSize=64, dropout=0.1, hiddenDim=200, loadBestModel=False, lr=0.004, modelType='models.Seq2SeqwithAttention', numEpochs=3000, numLayers=2, printEveryIters=400, savedModelDir='./saved_models/seq2seq_withAtten_200hid_2lyrs', seed=0, tbDescr='seq2seq_withAtten_dropout-0p1_hiddim-200_numlyrs-2_full-de-vocab', toTrain=True)\n","2021-04-18 17:47:32.277809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","Saver will maximize rouge-1...\n","After Iteration 0, Loss is: 9.286219\n","\tModel eval on training data after iteration 0...\n","\t\tRouge-1 is 0.0000, Rouge-2 is 0.0000, and Rouge-l is 0.0000\n","\tModel eval on validation data after iteration 0...\n","\t\tRouge-1 is 0.0000, Rouge-2 is 0.0000, and Rouge-l is 0.0000\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_0.pth.tar\n","New best checkpoint at step 0...\n","After Iteration 400, Loss is: 3.036758\n","\tModel eval on training data after iteration 400...\n","\t\tRouge-1 is 0.0938, Rouge-2 is 0.0131, and Rouge-l is 0.1238\n","\tModel eval on validation data after iteration 400...\n","\t\tRouge-1 is 0.0911, Rouge-2 is 0.0169, and Rouge-l is 0.1099\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_400.pth.tar\n","New best checkpoint at step 400...\n","After Iteration 800, Loss is: 2.332881\n","\tModel eval on training data after iteration 800...\n","\t\tRouge-1 is 0.2020, Rouge-2 is 0.0338, and Rouge-l is 0.2183\n","\tModel eval on validation data after iteration 800...\n","\t\tRouge-1 is 0.1922, Rouge-2 is 0.0347, and Rouge-l is 0.2124\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_800.pth.tar\n","New best checkpoint at step 800...\n","After Iteration 1200, Loss is: 1.466484\n","\tModel eval on training data after iteration 1200...\n","\t\tRouge-1 is 0.3062, Rouge-2 is 0.0512, and Rouge-l is 0.2156\n","\tModel eval on validation data after iteration 1200...\n","\t\tRouge-1 is 0.2941, Rouge-2 is 0.0498, and Rouge-l is 0.2024\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_1200.pth.tar\n","New best checkpoint at step 1200...\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_0.pth.tar\n","After Iteration 1600, Loss is: 0.495945\n","\tModel eval on training data after iteration 1600...\n","\t\tRouge-1 is 0.2016, Rouge-2 is 0.0155, and Rouge-l is 0.1716\n","\tModel eval on validation data after iteration 1600...\n","\t\tRouge-1 is 0.2162, Rouge-2 is 0.0081, and Rouge-l is 0.1720\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_1600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_400.pth.tar\n","After Iteration 2000, Loss is: 0.130167\n","\tModel eval on training data after iteration 2000...\n","\t\tRouge-1 is 0.2758, Rouge-2 is 0.0474, and Rouge-l is 0.2130\n","\tModel eval on validation data after iteration 2000...\n","\t\tRouge-1 is 0.2459, Rouge-2 is 0.0157, and Rouge-l is 0.1794\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_2000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_800.pth.tar\n","After Iteration 2400, Loss is: 0.072379\n","\tModel eval on training data after iteration 2400...\n","\t\tRouge-1 is 0.2636, Rouge-2 is 0.0314, and Rouge-l is 0.2010\n","\tModel eval on validation data after iteration 2400...\n","\t\tRouge-1 is 0.2459, Rouge-2 is 0.0157, and Rouge-l is 0.1794\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_2400.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_1600.pth.tar\n","After Iteration 2800, Loss is: 0.053606\n","\tModel eval on training data after iteration 2800...\n","\t\tRouge-1 is 0.2441, Rouge-2 is 0.0412, and Rouge-l is 0.1723\n","\tModel eval on validation data after iteration 2800...\n","\t\tRouge-1 is 0.2373, Rouge-2 is 0.0222, and Rouge-l is 0.1694\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_2800.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_2800.pth.tar\n","After Iteration 3200, Loss is: 0.050385\n","\tModel eval on training data after iteration 3200...\n","\t\tRouge-1 is 0.2791, Rouge-2 is 0.0472, and Rouge-l is 0.2145\n","\tModel eval on validation data after iteration 3200...\n","\t\tRouge-1 is 0.2459, Rouge-2 is 0.0157, and Rouge-l is 0.1794\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_3200.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_2000.pth.tar\n","After Iteration 3600, Loss is: 0.045236\n","\tModel eval on training data after iteration 3600...\n","\t\tRouge-1 is 0.2404, Rouge-2 is 0.0383, and Rouge-l is 0.1703\n","\tModel eval on validation data after iteration 3600...\n","\t\tRouge-1 is 0.2373, Rouge-2 is 0.0222, and Rouge-l is 0.1694\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_3600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_3600.pth.tar\n","After Iteration 4000, Loss is: 0.043499\n","\tModel eval on training data after iteration 4000...\n","\t\tRouge-1 is 0.2149, Rouge-2 is 0.0443, and Rouge-l is 0.2148\n","\tModel eval on validation data after iteration 4000...\n","\t\tRouge-1 is 0.1934, Rouge-2 is 0.0114, and Rouge-l is 0.1893\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_4000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_4000.pth.tar\n","After Iteration 4400, Loss is: 0.044165\n","\tModel eval on training data after iteration 4400...\n","\t\tRouge-1 is 0.2327, Rouge-2 is 0.0237, and Rouge-l is 0.1621\n","\tModel eval on validation data after iteration 4400...\n","\t\tRouge-1 is 0.2348, Rouge-2 is 0.0214, and Rouge-l is 0.1665\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_4400.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_4400.pth.tar\n","After Iteration 4800, Loss is: 0.042027\n","\tModel eval on training data after iteration 4800...\n","\t\tRouge-1 is 0.2688, Rouge-2 is 0.0344, and Rouge-l is 0.2033\n","\tModel eval on validation data after iteration 4800...\n","\t\tRouge-1 is 0.2459, Rouge-2 is 0.0157, and Rouge-l is 0.1794\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_4800.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_2400.pth.tar\n","After Iteration 5200, Loss is: 0.040503\n","\tModel eval on training data after iteration 5200...\n","\t\tRouge-1 is 0.2611, Rouge-2 is 0.0544, and Rouge-l is 0.1897\n","\tModel eval on validation data after iteration 5200...\n","\t\tRouge-1 is 0.2373, Rouge-2 is 0.0222, and Rouge-l is 0.1694\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_5200.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_5200.pth.tar\n","After Iteration 5600, Loss is: 0.039627\n","\tModel eval on training data after iteration 5600...\n","\t\tRouge-1 is 0.2690, Rouge-2 is 0.0321, and Rouge-l is 0.2037\n","\tModel eval on validation data after iteration 5600...\n","\t\tRouge-1 is 0.2459, Rouge-2 is 0.0157, and Rouge-l is 0.1794\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_5600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_5600.pth.tar\n","\n","Model eval on validation data after final iteration...\n","Example\n","Prediction\n","--start-- a method of producing and arrangement for a multi - pane insulating glass structure which has two parallel panes , a frame for holding the panes and an adhesive sealant mounted between the panes and the frame , comprises specially - shaped elongated plastic sectional rods forming portions of the frame and having grooves for receiving the panes with a foil - type vapor seal mounted intermediate first and second ones of the sectional rod portions . the first rod portion is substantially u - shaped in cross - section and forms a spacer for the spaced parallel panes . the u - shaped sectional rod includes a central web for spanning the foil - type vapor seal and forming a chamber for housing a moisture - absorbing agent . --stop--\n","Target\n","a collector for dog droppings includes a stick provided with a support bell at its ground - side end . the stick includes at its lower end an extension which projects through the support bell and is rotatable relative thereto . connected to the extension is a receiving insert which includes two semicircular plates with one plate movable relative to the other stationary plate so that the insert can be opened and closed for collecting and retaining the waste in the collector and for subsequent disposal thereof . --stop--                                           \n","For this example, Rouge-1 is 0.2232, Rouge-2 is 0.0204, and Rouge-l is 0.1621\n","\n","\tRouge-1 is 0.2232, Rouge-2 is 0.0204, and Rouge-l is 0.1621\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_6000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs/step_6000.pth.tar\n","1 loop, best of 1: 1h 58min 39s per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zacgmBPaKckK"},"source":["Training Loss |Training Data Rouge | Validation Data Rouge\n","--- | --- | ---\n","![](https://drive.google.com/uc?export=view&id=1d26RtIVDwygkh3A_Lq3v4eFR-RCK3ZbA) | ![](https://drive.google.com/uc?export=view&id=1xMBiCByW-57N7i-_Brd8o3Rmnc-pJFnA) | ![](https://drive.google.com/uc?export=view&id=1q4GQOM8M7fsxe4qaahFOaUEqDKqO6Xel)\n","| Dark Blue: Rouge-1, Red: Rouge-2, Light Blue: Rouge-l | Pink: Rouge-1, Green: Rouge-2, Gray: Rouge-l\n","\n","\n","Note that the initial loss will be approximately -log(abstract_vocab_size) because the model is randomly initialized.\n","\n","Best checkpoint at 1200: Rouge-1 is 0.2941, Rouge-2 is 0.0498, and Rouge-l is 0.2024\n"]},{"cell_type":"code","metadata":{"id":"3UvG4sRknvWV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQf6zg5CnvZf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KLRNOrkqnwOe"},"source":["#### Seq2Seq with Atten: lr=0.004, dropout=0.4, hiddim=200, numlyrs=2, full-de-vocab, train_size=128, val_size=16"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWnv-qM4nwOf","executionInfo":{"status":"ok","timestamp":1618791831353,"user_tz":420,"elapsed":4773241,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"88f372d0-0c00-487e-f986-ae3fcbe5cadb"},"source":["%%timeit -r 1 -n 1\n","#with attention\n","!python ./src/train.py --hiddenDim 200 --numLayers 2 --batchSize 64 --numEpochs 3000 --lr 4e-3 --savedModelDir './saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout' \\\n","                        --printEveryIters 400 --tbDescr 'seq2seq_withAtten_dropout-0p4_hiddim-200_numlyrs-2_full-de-vocab' \\\n","                        --modelType 'models.Seq2SeqwithAttention' --loadBestModel False --toTrain True \\\n","                        --dropout 0.4"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Getting the training data...\n","Size of description vocab is 36828 and abstract vocab is 10769\n","tcmalloc: large alloc 2406391808 bytes == 0x55c6459b2000 @  0x7f66719d51e7 0x55c5caf76f48 0x7f664854753e 0x7f6648547cd9 0x7f6648547faf 0x7f66485454b4 0x55c5caf450e4 0x55c5caf44de0 0x55c5cafb96f5 0x55c5caf4669a 0x55c5cafb4c9e 0x55c5caf4669a 0x55c5cafb4c9e 0x55c5caf4669a 0x55c5cafb4c9e 0x55c5caf4669a 0x55c5cafb4c9e 0x55c5cafb3b0e 0x55c5cae85e2b 0x55c5cafb61e6 0x55c5cafb3e0d 0x55c5cae85e2b 0x55c5cafb61e6 0x55c5cafb3e0d 0x55c5caf4677a 0x55c5cafb586a 0x55c5cb037858 0x55c5cafb4ee2 0x55c5cafb3b0e 0x55c5caf4677a 0x55c5cafb586a\n","max length (before adding stop token) in mini_df.description is 3943 and in mini_df.abstract (before adding start/stop tokens) is 147\n","(128, 4)\n","max length (before adding stop token) in mini_df.description is 3993 and in mini_df.abstract (before adding start/stop tokens) is 140\n","(16, 4)\n","Data shape is: torch.Size([128, 4000]), torch.Size([128, 150]), torch.Size([128])\n","Total data size is: 2.125MB\n","Data shape is: torch.Size([16, 4000]), torch.Size([16, 150]), torch.Size([16])\n","\n","Starting model training...\n","Namespace(batchSize=64, dropout=0.4, hiddenDim=200, loadBestModel=False, lr=0.004, modelType='models.Seq2SeqwithAttention', numEpochs=3000, numLayers=2, printEveryIters=400, savedModelDir='./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout', seed=0, tbDescr='seq2seq_withAtten_dropout-0p4_hiddim-200_numlyrs-2_full-de-vocab', toTrain=True)\n","2021-04-18 22:25:09.326091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","Saver will maximize rouge-1...\n","After Iteration 0, Loss is: 9.286187\n","\tModel eval on training data after iteration 0...\n","\t\tRouge-1 is 0.0000, Rouge-2 is 0.0000, and Rouge-l is 0.0000\n","\tModel eval on validation data after iteration 0...\n","\t\tRouge-1 is 0.0000, Rouge-2 is 0.0000, and Rouge-l is 0.0000\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_0.pth.tar\n","New best checkpoint at step 0...\n","After Iteration 400, Loss is: 3.129832\n","\tModel eval on training data after iteration 400...\n","\t\tRouge-1 is 0.1194, Rouge-2 is 0.0150, and Rouge-l is 0.1415\n","\tModel eval on validation data after iteration 400...\n","\t\tRouge-1 is 0.1112, Rouge-2 is 0.0184, and Rouge-l is 0.1243\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_400.pth.tar\n","New best checkpoint at step 400...\n","After Iteration 800, Loss is: 2.556950\n","\tModel eval on training data after iteration 800...\n","\t\tRouge-1 is 0.2351, Rouge-2 is 0.0392, and Rouge-l is 0.2532\n","\tModel eval on validation data after iteration 800...\n","\t\tRouge-1 is 0.2247, Rouge-2 is 0.0349, and Rouge-l is 0.2334\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_800.pth.tar\n","New best checkpoint at step 800...\n","After Iteration 1200, Loss is: 1.867382\n","\tModel eval on training data after iteration 1200...\n","\t\tRouge-1 is 0.2913, Rouge-2 is 0.0361, and Rouge-l is 0.2209\n","\tModel eval on validation data after iteration 1200...\n","\t\tRouge-1 is 0.2935, Rouge-2 is 0.0382, and Rouge-l is 0.2242\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_1200.pth.tar\n","New best checkpoint at step 1200...\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_0.pth.tar\n","After Iteration 1600, Loss is: 1.303139\n","\tModel eval on training data after iteration 1600...\n","\t\tRouge-1 is 0.2413, Rouge-2 is 0.0228, and Rouge-l is 0.2023\n","\tModel eval on validation data after iteration 1600...\n","\t\tRouge-1 is 0.2541, Rouge-2 is 0.0235, and Rouge-l is 0.2018\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_1600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_400.pth.tar\n","After Iteration 2000, Loss is: 0.731795\n","\tModel eval on training data after iteration 2000...\n","\t\tRouge-1 is 0.2775, Rouge-2 is 0.0379, and Rouge-l is 0.1978\n","\tModel eval on validation data after iteration 2000...\n","\t\tRouge-1 is 0.2555, Rouge-2 is 0.0202, and Rouge-l is 0.1721\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_2000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_800.pth.tar\n","After Iteration 2400, Loss is: 0.331043\n","\tModel eval on training data after iteration 2400...\n","\t\tRouge-1 is 0.2480, Rouge-2 is 0.0209, and Rouge-l is 0.1858\n","\tModel eval on validation data after iteration 2400...\n","\t\tRouge-1 is 0.2424, Rouge-2 is 0.0166, and Rouge-l is 0.1912\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_2400.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_2400.pth.tar\n","After Iteration 2800, Loss is: 0.192522\n","\tModel eval on training data after iteration 2800...\n","\t\tRouge-1 is 0.2606, Rouge-2 is 0.0323, and Rouge-l is 0.2009\n","\tModel eval on validation data after iteration 2800...\n","\t\tRouge-1 is 0.2432, Rouge-2 is 0.0164, and Rouge-l is 0.1791\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_2800.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_2800.pth.tar\n","After Iteration 3200, Loss is: 0.135118\n","\tModel eval on training data after iteration 3200...\n","\t\tRouge-1 is 0.2668, Rouge-2 is 0.0323, and Rouge-l is 0.2003\n","\tModel eval on validation data after iteration 3200...\n","\t\tRouge-1 is 0.2432, Rouge-2 is 0.0164, and Rouge-l is 0.1791\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_3200.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_3200.pth.tar\n","After Iteration 3600, Loss is: 0.112725\n","\tModel eval on training data after iteration 3600...\n","\t\tRouge-1 is 0.2289, Rouge-2 is 0.0240, and Rouge-l is 0.1582\n","\tModel eval on validation data after iteration 3600...\n","\t\tRouge-1 is 0.2321, Rouge-2 is 0.0209, and Rouge-l is 0.1630\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_3600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_3600.pth.tar\n","After Iteration 4000, Loss is: 0.091181\n","\tModel eval on training data after iteration 4000...\n","\t\tRouge-1 is 0.2560, Rouge-2 is 0.0178, and Rouge-l is 0.1843\n","\tModel eval on validation data after iteration 4000...\n","\t\tRouge-1 is 0.2432, Rouge-2 is 0.0164, and Rouge-l is 0.1791\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_4000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_4000.pth.tar\n","After Iteration 4400, Loss is: 0.088205\n","\tModel eval on training data after iteration 4400...\n","\t\tRouge-1 is 0.2096, Rouge-2 is 0.0149, and Rouge-l is 0.1709\n","\tModel eval on validation data after iteration 4400...\n","\t\tRouge-1 is 0.2074, Rouge-2 is 0.0122, and Rouge-l is 0.1528\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_4400.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_4400.pth.tar\n","After Iteration 4800, Loss is: 0.080485\n","\tModel eval on training data after iteration 4800...\n","\t\tRouge-1 is 0.2688, Rouge-2 is 0.0344, and Rouge-l is 0.2033\n","\tModel eval on validation data after iteration 4800...\n","\t\tRouge-1 is 0.2432, Rouge-2 is 0.0164, and Rouge-l is 0.1791\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_4800.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_4800.pth.tar\n","After Iteration 5200, Loss is: 0.076608\n","\tModel eval on training data after iteration 5200...\n","\t\tRouge-1 is 0.2503, Rouge-2 is 0.0397, and Rouge-l is 0.1766\n","\tModel eval on validation data after iteration 5200...\n","\t\tRouge-1 is 0.2382, Rouge-2 is 0.0225, and Rouge-l is 0.1643\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_5200.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_5200.pth.tar\n","After Iteration 5600, Loss is: 0.076436\n","\tModel eval on training data after iteration 5600...\n","\t\tRouge-1 is 0.2568, Rouge-2 is 0.0396, and Rouge-l is 0.1907\n","\tModel eval on validation data after iteration 5600...\n","\t\tRouge-1 is 0.2317, Rouge-2 is 0.0238, and Rouge-l is 0.1795\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_5600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_5600.pth.tar\n","\n","Model eval on validation data after final iteration...\n","Example\n","Prediction\n","--start-- a method of producing a fiber reinforced concrete structure of desired thickness including the steps of extruding a sheet of concrete substantially free of fibers , distributing an effective amount of reinforcing fibers on the sheet , repeating the foregoing steps until the desired thickness is --oov-- and before the concrete sheets have set up , and extruding a further sheet of substantially fiber - free concrete over the structure resulting from the foregoing steps to achieve the desired thickness . the amount of fiber distributed over each sheet may be varied to concentrate the fiber in the areas where the greatest stress concentration is expected . also disclosed is an apparatus for performing the method . --stop--              \n","Target\n","a collector for dog droppings includes a stick provided with a support bell at its ground - side end . the stick includes at its lower end an extension which projects through the support bell and is rotatable relative thereto . connected to the extension is a receiving insert which includes two semicircular plates with one plate movable relative to the other stationary plate so that the insert can be opened and closed for collecting and retaining the waste in the collector and for subsequent disposal thereof . --stop--                                            \n","For this example, Rouge-1 is 0.2470, Rouge-2 is 0.0156, and Rouge-l is 0.1775\n","\n","\tRouge-1 is 0.2470, Rouge-2 is 0.0156, and Rouge-l is 0.1775\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_6000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p4dropout/step_6000.pth.tar\n","1 loop, best of 1: 1h 59min per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XFFkHUj0kk2t"},"source":["Training Loss |Training Data Rouge | Validation Data Rouge\n","--- | --- | ---\n","![](https://drive.google.com/uc?export=view&id=1dX5GYaPXYXegue-OS67ak4sfSyFEV997) | ![](https://drive.google.com/uc?export=view&id=138SJejuTlbeqKcuNbjcek-bbwyILMSiq) | ![](https://drive.google.com/uc?export=view&id=1OplXxb3_m7rE-90CUwJ2w8wPQO6aDq9o)\n","| Dark Blue: Rouge-1, Red: Rouge-2, Light Blue: Rouge-l | Pink: Rouge-1, Green: Rouge-2, Gray: Rouge-l\n","\n","Note that the initial loss will be approximately -log(abstract_vocab_size) because the model is randomly initialized.\n","\n","Best checkpoint at 1200: Rouge-1 is 0.2935, Rouge-2 is 0.0382, and Rouge-l is 0.2242\n","\n","Didn't see much difference even with dropout of 0.75. "]},{"cell_type":"code","metadata":{"id":"RvxvD3dJ5Lsq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZEARMqas5Lw0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uJyK7Xlaloh7"},"source":["#### Seq2Seq with Atten: lr=0.004, dropout=0.4 and 0.0, hiddim=200, numlyrs=2, full-de-vocab, train_size=1024, val_size=16\n","\n","But did not notice much improvement in R1/R2 scores"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXoR7wchloh8","executionInfo":{"status":"ok","timestamp":1618867071384,"user_tz":420,"elapsed":14740192,"user":{"displayName":"Amit Patel","photoUrl":"","userId":"14428842836414406555"}},"outputId":"7ec984b7-0d1f-4dc8-eb59-814ee51576cd"},"source":["%%timeit -r 1 -n 1\n","#with attention\n","!python ./src/train.py --hiddenDim 200 --numLayers 2 --batchSize 64 --numEpochs 3000 --lr 4e-3 --savedModelDir './saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout' \\\n","                        --printEveryIters 400 --tbDescr 'seq2seq_withAtten_dropout-0p0_hiddim-200_numlyrs-2_full-de-vocab_train-1024' \\\n","                        --modelType 'models.Seq2SeqwithAttention' --loadBestModel False --toTrain True \\\n","                        --dropout 0.0"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Getting the training data...\n","Size of description vocab is 36828 and abstract vocab is 10769\n","tcmalloc: large alloc 2406391808 bytes == 0x5629c0fd6000 @  0x7fbedfc1d1e7 0x56294632df48 0x7fbeb678f53e 0x7fbeb678fcd9 0x7fbeb678ffaf 0x7fbeb678d4b4 0x5629462fc0e4 0x5629462fbde0 0x5629463706f5 0x5629462fd69a 0x56294636bc9e 0x5629462fd69a 0x56294636bc9e 0x5629462fd69a 0x56294636bc9e 0x5629462fd69a 0x56294636bc9e 0x56294636ab0e 0x56294623ce2b 0x56294636d1e6 0x56294636ae0d 0x56294623ce2b 0x56294636d1e6 0x56294636ae0d 0x5629462fd77a 0x56294636c86a 0x5629463ee858 0x56294636bee2 0x56294636ab0e 0x5629462fd77a 0x56294636c86a\n","max length (before adding stop token) in mini_df.description is 3996 and in mini_df.abstract (before adding start/stop tokens) is 149\n","(1024, 4)\n","max length (before adding stop token) in mini_df.description is 3993 and in mini_df.abstract (before adding start/stop tokens) is 140\n","(16, 4)\n","Data shape is: torch.Size([1024, 4000]), torch.Size([1024, 150]), torch.Size([1024])\n","Total data size is: 16.999MB\n","Data shape is: torch.Size([16, 4000]), torch.Size([16, 150]), torch.Size([16])\n","\n","Starting model training...\n","Namespace(batchSize=64, dropout=0.0, hiddenDim=200, loadBestModel=False, lr=0.004, modelType='models.Seq2SeqwithAttention', numEpochs=3000, numLayers=2, printEveryIters=400, savedModelDir='./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout', seed=0, tbDescr='seq2seq_withAtten_dropout-0p0_hiddim-200_numlyrs-2_full-de-vocab_train-1024', toTrain=True)\n","2021-04-19 17:12:29.716495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","Saver will maximize rouge-1...\n","After Iteration 0, Loss is: 9.303008\n","\tModel eval on training data after iteration 0...\n","\t\tRouge-1 is 0.0000, Rouge-2 is 0.0000, and Rouge-l is 0.0000\n","\tModel eval on validation data after iteration 0...\n","\t\tRouge-1 is 0.0000, Rouge-2 is 0.0000, and Rouge-l is 0.0000\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_0.pth.tar\n","New best checkpoint at step 0...\n","After Iteration 400, Loss is: 3.704815\n","\tModel eval on training data after iteration 400...\n","\t\tRouge-1 is 0.0361, Rouge-2 is 0.0000, and Rouge-l is 0.0396\n","\tModel eval on validation data after iteration 400...\n","\t\tRouge-1 is 0.0433, Rouge-2 is 0.0000, and Rouge-l is 0.0307\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_400.pth.tar\n","New best checkpoint at step 400...\n","After Iteration 800, Loss is: 3.995556\n","\tModel eval on training data after iteration 800...\n","\t\tRouge-1 is 0.0546, Rouge-2 is 0.0000, and Rouge-l is 0.0391\n","\tModel eval on validation data after iteration 800...\n","\t\tRouge-1 is 0.0544, Rouge-2 is 0.0000, and Rouge-l is 0.0397\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_800.pth.tar\n","New best checkpoint at step 800...\n","After Iteration 1200, Loss is: 4.290141\n","\tModel eval on training data after iteration 1200...\n","\t\tRouge-1 is 0.0633, Rouge-2 is 0.0000, and Rouge-l is 0.0743\n","\tModel eval on validation data after iteration 1200...\n","\t\tRouge-1 is 0.0599, Rouge-2 is 0.0000, and Rouge-l is 0.0673\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_1200.pth.tar\n","New best checkpoint at step 1200...\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_0.pth.tar\n","After Iteration 1600, Loss is: 4.185345\n","\tModel eval on training data after iteration 1600...\n","\t\tRouge-1 is 0.0878, Rouge-2 is 0.0000, and Rouge-l is 0.0761\n","\tModel eval on validation data after iteration 1600...\n","\t\tRouge-1 is 0.0932, Rouge-2 is 0.0000, and Rouge-l is 0.0689\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_1600.pth.tar\n","New best checkpoint at step 1600...\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_400.pth.tar\n","After Iteration 2000, Loss is: 3.324567\n","\tModel eval on training data after iteration 2000...\n","\t\tRouge-1 is 0.0137, Rouge-2 is 0.0000, and Rouge-l is 0.0546\n","\tModel eval on validation data after iteration 2000...\n","\t\tRouge-1 is 0.0145, Rouge-2 is 0.0000, and Rouge-l is 0.0501\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_2000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_2000.pth.tar\n","After Iteration 2400, Loss is: 3.255246\n","\tModel eval on training data after iteration 2400...\n","\t\tRouge-1 is 0.1161, Rouge-2 is 0.0101, and Rouge-l is 0.1830\n","\tModel eval on validation data after iteration 2400...\n","\t\tRouge-1 is 0.1305, Rouge-2 is 0.0102, and Rouge-l is 0.1576\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_2400.pth.tar\n","New best checkpoint at step 2400...\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_800.pth.tar\n","After Iteration 2800, Loss is: 2.526817\n","\tModel eval on training data after iteration 2800...\n","\t\tRouge-1 is 0.1897, Rouge-2 is 0.0269, and Rouge-l is 0.2240\n","\tModel eval on validation data after iteration 2800...\n","\t\tRouge-1 is 0.1951, Rouge-2 is 0.0284, and Rouge-l is 0.2071\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_2800.pth.tar\n","New best checkpoint at step 2800...\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_1200.pth.tar\n","After Iteration 3200, Loss is: 2.080540\n","\tModel eval on training data after iteration 3200...\n","\t\tRouge-1 is 0.1311, Rouge-2 is 0.0183, and Rouge-l is 0.1597\n","\tModel eval on validation data after iteration 3200...\n","\t\tRouge-1 is 0.1274, Rouge-2 is 0.0162, and Rouge-l is 0.1479\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_3200.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_1600.pth.tar\n","After Iteration 3600, Loss is: 1.575231\n","\tModel eval on training data after iteration 3600...\n","\t\tRouge-1 is 0.2812, Rouge-2 is 0.0365, and Rouge-l is 0.2022\n","\tModel eval on validation data after iteration 3600...\n","\t\tRouge-1 is 0.2880, Rouge-2 is 0.0269, and Rouge-l is 0.1927\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_3600.pth.tar\n","New best checkpoint at step 3600...\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_3200.pth.tar\n","After Iteration 4000, Loss is: 1.187322\n","\tModel eval on training data after iteration 4000...\n","\t\tRouge-1 is 0.1904, Rouge-2 is 0.0291, and Rouge-l is 0.1801\n","\tModel eval on validation data after iteration 4000...\n","\t\tRouge-1 is 0.1914, Rouge-2 is 0.0279, and Rouge-l is 0.1750\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_4000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_2400.pth.tar\n","After Iteration 4400, Loss is: 0.970687\n","\tModel eval on training data after iteration 4400...\n","\t\tRouge-1 is 0.2757, Rouge-2 is 0.0419, and Rouge-l is 0.2001\n","\tModel eval on validation data after iteration 4400...\n","\t\tRouge-1 is 0.2684, Rouge-2 is 0.0318, and Rouge-l is 0.1813\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_4400.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_4000.pth.tar\n","After Iteration 4800, Loss is: 0.791774\n","\tModel eval on training data after iteration 4800...\n","\t\tRouge-1 is 0.2953, Rouge-2 is 0.0398, and Rouge-l is 0.1874\n","\tModel eval on validation data after iteration 4800...\n","\t\tRouge-1 is 0.2636, Rouge-2 is 0.0309, and Rouge-l is 0.1782\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_4800.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_2800.pth.tar\n","After Iteration 5200, Loss is: 0.524312\n","\tModel eval on training data after iteration 5200...\n","\t\tRouge-1 is 0.2386, Rouge-2 is 0.0403, and Rouge-l is 0.1545\n","\tModel eval on validation data after iteration 5200...\n","\t\tRouge-1 is 0.2363, Rouge-2 is 0.0399, and Rouge-l is 0.1443\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_5200.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_5200.pth.tar\n","After Iteration 5600, Loss is: 0.391389\n","\tModel eval on training data after iteration 5600...\n","\t\tRouge-1 is 0.2237, Rouge-2 is 0.0160, and Rouge-l is 0.1705\n","\tModel eval on validation data after iteration 5600...\n","\t\tRouge-1 is 0.2285, Rouge-2 is 0.0135, and Rouge-l is 0.1643\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_5600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_5600.pth.tar\n","After Iteration 6000, Loss is: 0.281203\n","\tModel eval on training data after iteration 6000...\n","\t\tRouge-1 is 0.2666, Rouge-2 is 0.0284, and Rouge-l is 0.1985\n","\tModel eval on validation data after iteration 6000...\n","\t\tRouge-1 is 0.2546, Rouge-2 is 0.0235, and Rouge-l is 0.1797\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_6000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_6000.pth.tar\n","After Iteration 6400, Loss is: 0.227652\n","\tModel eval on training data after iteration 6400...\n","\t\tRouge-1 is 0.2633, Rouge-2 is 0.0239, and Rouge-l is 0.1796\n","\tModel eval on validation data after iteration 6400...\n","\t\tRouge-1 is 0.2427, Rouge-2 is 0.0126, and Rouge-l is 0.1499\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_6400.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_6400.pth.tar\n","After Iteration 6800, Loss is: 0.190967\n","\tModel eval on training data after iteration 6800...\n","\t\tRouge-1 is 0.2080, Rouge-2 is 0.0163, and Rouge-l is 0.1478\n","\tModel eval on validation data after iteration 6800...\n","\t\tRouge-1 is 0.2028, Rouge-2 is 0.0143, and Rouge-l is 0.1624\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_6800.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_6800.pth.tar\n","After Iteration 7200, Loss is: 0.142567\n","\tModel eval on training data after iteration 7200...\n","\t\tRouge-1 is 0.2899, Rouge-2 is 0.0462, and Rouge-l is 0.1944\n","\tModel eval on validation data after iteration 7200...\n","\t\tRouge-1 is 0.2804, Rouge-2 is 0.0385, and Rouge-l is 0.1913\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_7200.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_4800.pth.tar\n","After Iteration 7600, Loss is: 0.110673\n","\tModel eval on training data after iteration 7600...\n","\t\tRouge-1 is 0.2760, Rouge-2 is 0.0402, and Rouge-l is 0.1779\n","\tModel eval on validation data after iteration 7600...\n","\t\tRouge-1 is 0.2732, Rouge-2 is 0.0421, and Rouge-l is 0.1665\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_7600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_4400.pth.tar\n","After Iteration 8000, Loss is: 0.095982\n","\tModel eval on training data after iteration 8000...\n","\t\tRouge-1 is 0.2554, Rouge-2 is 0.0315, and Rouge-l is 0.1835\n","\tModel eval on validation data after iteration 8000...\n","\t\tRouge-1 is 0.2372, Rouge-2 is 0.0301, and Rouge-l is 0.1731\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_8000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_8000.pth.tar\n","After Iteration 8400, Loss is: 0.088561\n","\tModel eval on training data after iteration 8400...\n","\t\tRouge-1 is 0.2460, Rouge-2 is 0.0338, and Rouge-l is 0.1917\n","\tModel eval on validation data after iteration 8400...\n","\t\tRouge-1 is 0.2300, Rouge-2 is 0.0314, and Rouge-l is 0.1827\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_8400.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_8400.pth.tar\n","After Iteration 8800, Loss is: 0.074466\n","\tModel eval on training data after iteration 8800...\n","\t\tRouge-1 is 0.2785, Rouge-2 is 0.0228, and Rouge-l is 0.2085\n","\tModel eval on validation data after iteration 8800...\n","\t\tRouge-1 is 0.2610, Rouge-2 is 0.0115, and Rouge-l is 0.1709\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_8800.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_8800.pth.tar\n","After Iteration 9200, Loss is: 0.460158\n","\tModel eval on training data after iteration 9200...\n","\t\tRouge-1 is 0.2603, Rouge-2 is 0.0368, and Rouge-l is 0.1737\n","\tModel eval on validation data after iteration 9200...\n","\t\tRouge-1 is 0.2530, Rouge-2 is 0.0346, and Rouge-l is 0.1642\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_9200.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_9200.pth.tar\n","After Iteration 9600, Loss is: 0.064838\n","\tModel eval on training data after iteration 9600...\n","\t\tRouge-1 is 0.2822, Rouge-2 is 0.0236, and Rouge-l is 0.2028\n","\tModel eval on validation data after iteration 9600...\n","\t\tRouge-1 is 0.2670, Rouge-2 is 0.0195, and Rouge-l is 0.1933\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_9600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_9600.pth.tar\n","After Iteration 10000, Loss is: 0.059815\n","\tModel eval on training data after iteration 10000...\n","\t\tRouge-1 is 0.2686, Rouge-2 is 0.0372, and Rouge-l is 0.1798\n","\tModel eval on validation data after iteration 10000...\n","\t\tRouge-1 is 0.2526, Rouge-2 is 0.0300, and Rouge-l is 0.1712\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_10000.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_10000.pth.tar\n","After Iteration 10400, Loss is: 0.058122\n","\tModel eval on training data after iteration 10400...\n","\t\tRouge-1 is 0.2809, Rouge-2 is 0.0294, and Rouge-l is 0.1839\n","\tModel eval on validation data after iteration 10400...\n","\t\tRouge-1 is 0.2737, Rouge-2 is 0.0405, and Rouge-l is 0.1855\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_10400.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_7600.pth.tar\n","After Iteration 10800, Loss is: 0.063380\n","\tModel eval on training data after iteration 10800...\n","\t\tRouge-1 is 0.2551, Rouge-2 is 0.0287, and Rouge-l is 0.1871\n","\tModel eval on validation data after iteration 10800...\n","\t\tRouge-1 is 0.2396, Rouge-2 is 0.0292, and Rouge-l is 0.1738\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_10800.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_10800.pth.tar\n","After Iteration 11200, Loss is: 0.060082\n","\tModel eval on training data after iteration 11200...\n","\t\tRouge-1 is 0.2639, Rouge-2 is 0.0410, and Rouge-l is 0.1861\n","\tModel eval on validation data after iteration 11200...\n","\t\tRouge-1 is 0.2555, Rouge-2 is 0.0318, and Rouge-l is 0.1720\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_11200.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_11200.pth.tar\n","After Iteration 11600, Loss is: 0.064270\n","\tModel eval on training data after iteration 11600...\n","\t\tRouge-1 is 0.2726, Rouge-2 is 0.0302, and Rouge-l is 0.1796\n","\tModel eval on validation data after iteration 11600...\n","\t\tRouge-1 is 0.2596, Rouge-2 is 0.0289, and Rouge-l is 0.1814\n","Saved checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_11600.pth.tar\n","Removed checkpoint: ./saved_models/seq2seq_withAtten_200hid_2lyrs_0p0dropout/step_11600.pth.tar\n","Traceback (most recent call last):\n","  File \"./src/train.py\", line 222, in <module>\n","    savedModelDir=args.savedModelDir, step=step, bestMetricVal=metricVal)\n","  File \"./src/train.py\", line 58, in train\n","    y = model(x, y)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/drive/My Drive/Colab Notebooks/UCSDX_MLE_Bootcamp/Text_Summarization_UCSD/ModelBuilding/src/models.py\", line 33, in forward\n","    hinit_dec, yEnc = self.encoder(x) #shape of hinit_dec is: L*D x B x H and shape of YEnc is B x Lenc x 2H\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/drive/My Drive/Colab Notebooks/UCSDX_MLE_Bootcamp/Text_Summarization_UCSD/ModelBuilding/src/models.py\", line 172, in forward\n","    y,(h,c) = self.LSTM(x, (h0,c0)) #h: numLyrs*numDirsxBxH\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\", line 665, in forward\n","    self.num_layers, self.dropout, self.training, self.bidirectional)\n","KeyboardInterrupt\n","1 loop, best of 1: 4h 5min 39s per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iz8W6Ih6ln1_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5RmexM3-ln54"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hw_xSqOu4jxy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tyrVj0AIfsth"},"source":["# import models\n","# import train\n","\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# train_data, val_data, lang_train = train.get_data(use_full_vocab=True, cpc_codes='de', fname='data0_str_json.gz',\n","#                                                     train_size=128, val_size=16)\n","\n","# encoder = models.EncoderLSTM(vocab_size=len(lang_train.desc_vocab), hidden_dim=50, num_layers=2, bidir=True)\n","# decoder = models.DecoderLSTM(vocab_size=len(lang_train.abs_vocab), hidden_dim=50, num_layers=2, bidir=False)\n","# model = models.Seq2Seq(encoder, decoder)\n","\n","# train_data.shuffle(2)\n","# val_data.shuffle(2)\n","\n","# train.train(model=model, train_data=train_data, val_data=val_data, abs_idx2word=lang_train.abs_idx2word, device=device, \n","#             batch_size=128, num_epochs=1, lr=2e-3, print_every_iters=250, tb_descr='zzzdropout-0_hiddim-50_numlyrs-2_full-de-data')\n","\n","#only do this once you are done with this notebook\n","# utils.closeLoggerFileHandler(train.logger)\n","# utils.closeLoggerFileHandler(train.evaluate.logger)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLY_1y6K_GB_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GK1FCrj8_GGR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_h5hwvTE_GKw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"doCKW0Uo_GOo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1cHQwXQfzw9"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a1SXmgbVMeEo"},"source":["## Visualization Using Tensorboard"]},{"cell_type":"code","metadata":{"id":"1sBZZ2Dn-mXL"},"source":["%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ivc8PTXYfbGn"},"source":["%tensorboard --logdir='runs'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MdVp4UCSUfGb"},"source":["## Future Experimentation\n","1. Use glove embeddings to initialize the embeddings layer\n","2. for decoder use initial value of h and c from encoder output or just h and initialize c with zero?\n","3. see if can get rid of stop token from the decription\n","4. use weight in the cross entropy loss proportional to the word counts in the abstract vocabulary\n","5. Use beam search\n","- Didn't make much difference. So revisit this byt looking at CS224n lecture slides on this (http://web.stanford.edu/class/cs224n/slides/cs224n-2021-lecture07-nmt.pdf)\n","6. add attention and make model larger (more lstm layers and increase hidden dim size)\n","7. use transformers\n","8. use teacher forcing only 50% of the time when training and not 100%\n","9. use some of the ideas documented as part of my literature survey\n","10. Other ideas to try:\n","- http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/\n","- https://towardsdatascience.com/abstractive-summarization-of-dialogues-f530c7d290be\n","- https://www.analyticsvidhya.com/blog/2021/02/dialogue-summarization-a-deep-learning-approach/\n","- https://www.analyticsvidhya.com/blog/2020/11/summarize-twitter-live-data-using-pretrained-nlp-models/"]},{"cell_type":"code","metadata":{"id":"_Z574Y5Vd3Eh"},"source":[""],"execution_count":null,"outputs":[]}]}